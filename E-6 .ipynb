{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25bc808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re \n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "173e70d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " [\"Now I've heard there was a secret chord\", 'That David played, and it pleased the Lord', \"But you don't really care for music, do you?\"]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96fdccb",
   "metadata": {},
   "source": [
    "### 총개수 187088개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01eaac0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187088"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cadba1",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "245399b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence . <end> \n"
     ]
    }
   ],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() \n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) \n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) \n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) \n",
    "    sentence = sentence.strip()\n",
    "    sentence = '<start> ' + sentence + ' <end> '\n",
    "    return sentence\n",
    "\n",
    "# 이 문장이 어떻게 필터링되는지 확인해 보세요.\n",
    "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c3a74a",
   "metadata": {},
   "source": [
    "### 정제한 결과 14120개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86b52af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14120\n",
      "['<start> hallelujah <end> ', '<start> hallelujah <end> ', '<start> she tied you <end> ', '<start> hallelujah <end> ', '<start> hallelujah <end> ', '<start> in every word <end> ', '<start> hallelujah <end> ', '<start> hallelujah <end> ', '<start> and even though <end> ', '<start> hallelujah <end> ']\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence) == 0: continue\n",
    "    if len(sentence) > 15: continue  # 공백 포함해서 합계 15 초과는 배제\n",
    "    if sentence[-1] == \":\": continue\n",
    "    \n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    corpus.append(preprocessed_sentence)\n",
    "        \n",
    "\n",
    "print(len(corpus[:])) # 정제한 결과는 14120개이다.\n",
    "print(corpus[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d96d272",
   "metadata": {},
   "source": [
    "### num_words에 14120개 기입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9a25aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2 162   3 ...   0   0   0]\n",
      " [  2 162   3 ...   0   0   0]\n",
      " [  2  56 881 ...   0   0   0]\n",
      " ...\n",
      " [  2 216 554 ...   0   0   0]\n",
      " [  2  60  17 ...   0   0   0]\n",
      " [  2  36  21 ...   0   0   0]] <keras_preprocessing.text.Tokenizer object at 0x7f8eb7a58f10>\n"
     ]
    }
   ],
   "source": [
    "def tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=14120,  \n",
    "        filters=' ',\n",
    "        oov_token=\"<unk>\"\n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
    "    \n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d8d9b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2 162   3   0   0   0   0   0   0   0   0   0]\n",
      "[162   3   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "src_input = tensor[:, :-1]  \n",
    "tgt_input = tensor[:, 1:]    \n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3a75103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 12), (256, 12)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1   \n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48a5079",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e205b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82e47fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 12, 14121), dtype=float32, numpy=\n",
       "array([[[ 8.58998392e-05,  2.89846266e-05,  6.92937829e-06, ...,\n",
       "         -1.09919289e-04,  1.15501789e-04, -3.58508150e-05],\n",
       "        [-2.08016590e-05, -3.95828238e-06, -9.97651296e-05, ...,\n",
       "         -2.42006630e-04,  1.35944283e-04,  2.73783517e-04],\n",
       "        [ 2.69058182e-05,  4.97728142e-05, -2.92374636e-04, ...,\n",
       "         -1.63932069e-04,  6.57883793e-05,  5.17553475e-04],\n",
       "        ...,\n",
       "        [-3.75499105e-04, -2.42668626e-04, -1.00314990e-03, ...,\n",
       "          1.74755976e-03, -1.62696710e-03, -2.18058727e-03],\n",
       "        [-5.52661368e-04, -4.92478663e-04, -8.91218719e-04, ...,\n",
       "          2.16150866e-03, -1.97396544e-03, -2.69659143e-03],\n",
       "        [-6.92180649e-04, -7.55017332e-04, -7.57718342e-04, ...,\n",
       "          2.53119576e-03, -2.26226193e-03, -3.13537265e-03]],\n",
       "\n",
       "       [[ 8.58998392e-05,  2.89846266e-05,  6.92937829e-06, ...,\n",
       "         -1.09919289e-04,  1.15501789e-04, -3.58508150e-05],\n",
       "        [-2.08016590e-05, -3.95828238e-06, -9.97651296e-05, ...,\n",
       "         -2.42006630e-04,  1.35944283e-04,  2.73783517e-04],\n",
       "        [ 6.05692439e-05, -3.38054495e-04, -3.56369157e-04, ...,\n",
       "         -2.41324597e-04,  9.02188185e-05,  4.17654170e-04],\n",
       "        ...,\n",
       "        [-7.87305908e-05, -1.01000238e-04, -1.59178593e-03, ...,\n",
       "          1.14797195e-03, -1.27626455e-03, -1.61869952e-03],\n",
       "        [-3.39416176e-04, -2.46752606e-04, -1.53270247e-03, ...,\n",
       "          1.64510193e-03, -1.63489208e-03, -2.28047371e-03],\n",
       "        [-5.69827156e-04, -4.44821548e-04, -1.42187811e-03, ...,\n",
       "          2.10128399e-03, -1.96089735e-03, -2.85212137e-03]],\n",
       "\n",
       "       [[ 8.58998392e-05,  2.89846266e-05,  6.92937829e-06, ...,\n",
       "         -1.09919289e-04,  1.15501789e-04, -3.58508150e-05],\n",
       "        [-1.45911879e-04, -1.52396915e-05,  7.91302155e-05, ...,\n",
       "         -2.12828396e-04,  2.57547887e-04, -2.46341020e-04],\n",
       "        [-6.50591683e-05,  3.97462136e-05, -9.62807680e-05, ...,\n",
       "         -2.43018774e-04,  4.70183120e-04, -3.23739834e-04],\n",
       "        ...,\n",
       "        [-9.83767211e-04, -8.51607416e-04, -3.75120784e-04, ...,\n",
       "          2.48440891e-03, -2.28744443e-03, -3.30448290e-03],\n",
       "        [-1.03305397e-03, -1.07912102e-03, -2.91434902e-04, ...,\n",
       "          2.81774160e-03, -2.53860420e-03, -3.60934716e-03],\n",
       "        [-1.05748442e-03, -1.29788055e-03, -1.98752809e-04, ...,\n",
       "          3.10342107e-03, -2.72630504e-03, -3.86574562e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 8.58998392e-05,  2.89846266e-05,  6.92937829e-06, ...,\n",
       "         -1.09919289e-04,  1.15501789e-04, -3.58508150e-05],\n",
       "        [ 1.06724605e-04, -8.36529071e-05,  6.51112277e-05, ...,\n",
       "         -5.88415773e-04,  1.50995475e-04,  4.32574525e-05],\n",
       "        [ 2.77106534e-04, -9.56865988e-05,  3.38554353e-04, ...,\n",
       "         -8.63163848e-04,  2.86112099e-05,  4.86572972e-04],\n",
       "        ...,\n",
       "        [-6.96762218e-05,  2.84885522e-04, -4.95129731e-04, ...,\n",
       "          9.35990771e-04, -1.32648414e-03, -1.47559936e-03],\n",
       "        [-2.85062386e-04,  4.10970315e-05, -5.19835041e-04, ...,\n",
       "          1.47149677e-03, -1.74822577e-03, -2.07140576e-03],\n",
       "        [-4.63713310e-04, -2.36347143e-04, -5.01843460e-04, ...,\n",
       "          1.96401495e-03, -2.10666051e-03, -2.59220018e-03]],\n",
       "\n",
       "       [[ 8.58998392e-05,  2.89846266e-05,  6.92937829e-06, ...,\n",
       "         -1.09919289e-04,  1.15501789e-04, -3.58508150e-05],\n",
       "        [ 5.78134313e-05,  7.64941869e-05, -1.23430334e-04, ...,\n",
       "         -2.21445036e-04,  1.71933516e-05,  1.47920378e-04],\n",
       "        [ 3.25231085e-05,  1.26341445e-04, -2.31348153e-04, ...,\n",
       "         -2.15680309e-04,  1.69831692e-04,  4.98537265e-04],\n",
       "        ...,\n",
       "        [-6.61799393e-04, -6.69374014e-04, -6.90187793e-04, ...,\n",
       "          2.06183898e-03, -2.05310527e-03, -2.60767783e-03],\n",
       "        [-7.74446642e-04, -9.44891828e-04, -5.95689286e-04, ...,\n",
       "          2.43102340e-03, -2.35954975e-03, -3.05647892e-03],\n",
       "        [-8.55980266e-04, -1.21027732e-03, -4.87411715e-04, ...,\n",
       "          2.75864592e-03, -2.59671523e-03, -3.43471160e-03]],\n",
       "\n",
       "       [[ 8.58998392e-05,  2.89846266e-05,  6.92937829e-06, ...,\n",
       "         -1.09919289e-04,  1.15501789e-04, -3.58508150e-05],\n",
       "        [ 3.11825279e-04,  5.34872779e-05, -6.68872162e-05, ...,\n",
       "         -1.36275936e-04,  3.70184607e-05, -2.18505855e-04],\n",
       "        [ 6.16569538e-04,  1.67757084e-04, -1.14681243e-04, ...,\n",
       "         -1.97019181e-04, -2.16002882e-05, -3.22392851e-04],\n",
       "        ...,\n",
       "        [-5.19360299e-04,  2.05309945e-04, -1.07221608e-03, ...,\n",
       "          1.86428952e-03, -2.21699569e-03, -2.75866617e-03],\n",
       "        [-7.61043630e-04, -7.65261429e-05, -1.00837054e-03, ...,\n",
       "          2.26671784e-03, -2.51136697e-03, -3.14978859e-03],\n",
       "        [-9.38909012e-04, -3.75037896e-04, -9.10250412e-04, ...,\n",
       "          2.62801186e-03, -2.73801875e-03, -3.49042006e-03]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "684686d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  3614976   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  14474025  \n",
      "=================================================================\n",
      "Total params: 31,728,681\n",
      "Trainable params: 31,728,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76f37c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "55/55 [==============================] - 11s 165ms/step - loss: 2.8643\n",
      "Epoch 2/3\n",
      "55/55 [==============================] - 9s 171ms/step - loss: 1.7553\n",
      "Epoch 3/3\n",
      "55/55 [==============================] - 9s 167ms/step - loss: 1.5915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8eb6f02190>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "model.fit(dataset, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7db923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 단어 하나씩 예측해 문장을 만듭니다\n",
    "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
    "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
    "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
    "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다\n",
    "    while True:\n",
    "        # 1\n",
    "        predict = model(test_tensor) \n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d354cb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> it <end> '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d450055a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a01b964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeec87f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9573c58a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5567d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd691262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
