{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32eece0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "# https://url.kr/ayorp2 참고 사이트\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = load_breast_cancer() # 원래는 cancer,breast_cancer 등으로 할려고 했으나 \n",
    "                            #자꾸 import가 되지 않았습니다.(type이 function)\n",
    "                            # 위쪽의 링크를 복사 붙여넣기를 하니 import가되어서 변수명을 data로 했습니다.\n",
    "\n",
    "\n",
    "print(data.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fc54769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n",
      "딕션너리 키:  dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
      "\n",
      "\n",
      "데이터: [[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n",
      "\n",
      "\n",
      "윤곽:  None\n",
      "\n",
      "\n",
      "문제지 이름(항목):  ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "\n",
      "\n",
      "정답지 이름(카테고리):  ['malignant' 'benign']\n",
      "\n",
      "\n",
      "정답지 번호(일련번호):  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
      "\n",
      "\n",
      "데이터 모듈:  sklearn.datasets.data\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(type(data))\n",
    "\n",
    "print('딕션너리 키: ', data.keys()); print('\\n') # 항목을 확인함.\n",
    "\n",
    "print('데이터:', data.data); print('\\n')\n",
    "print('윤곽: ', data.frame); print('\\n')\n",
    "print('문제지 이름(항목): ', data.feature_names); print('\\n')\n",
    "print('정답지 이름(카테고리): ', data.target_names); print('\\n')\n",
    "print('정답지 번호(일련번호): ', data.target); print('\\n')\n",
    "print('데이터 모듈: ', data.data_module); print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcd42605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(569,)\n",
      "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0          17.99         10.38          122.80     1001.0          0.11840   \n",
      "1          20.57         17.77          132.90     1326.0          0.08474   \n",
      "2          19.69         21.25          130.00     1203.0          0.10960   \n",
      "3          11.42         20.38           77.58      386.1          0.14250   \n",
      "4          20.29         14.34          135.10     1297.0          0.10030   \n",
      "..           ...           ...             ...        ...              ...   \n",
      "564        21.56         22.39          142.00     1479.0          0.11100   \n",
      "565        20.13         28.25          131.20     1261.0          0.09780   \n",
      "566        16.60         28.08          108.30      858.1          0.08455   \n",
      "567        20.60         29.33          140.10     1265.0          0.11780   \n",
      "568         7.76         24.54           47.92      181.0          0.05263   \n",
      "\n",
      "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0             0.27760         0.30010              0.14710         0.2419   \n",
      "1             0.07864         0.08690              0.07017         0.1812   \n",
      "2             0.15990         0.19740              0.12790         0.2069   \n",
      "3             0.28390         0.24140              0.10520         0.2597   \n",
      "4             0.13280         0.19800              0.10430         0.1809   \n",
      "..                ...             ...                  ...            ...   \n",
      "564           0.11590         0.24390              0.13890         0.1726   \n",
      "565           0.10340         0.14400              0.09791         0.1752   \n",
      "566           0.10230         0.09251              0.05302         0.1590   \n",
      "567           0.27700         0.35140              0.15200         0.2397   \n",
      "568           0.04362         0.00000              0.00000         0.1587   \n",
      "\n",
      "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                   0.07871  ...          17.33           184.60      2019.0   \n",
      "1                   0.05667  ...          23.41           158.80      1956.0   \n",
      "2                   0.05999  ...          25.53           152.50      1709.0   \n",
      "3                   0.09744  ...          26.50            98.87       567.7   \n",
      "4                   0.05883  ...          16.67           152.20      1575.0   \n",
      "..                      ...  ...            ...              ...         ...   \n",
      "564                 0.05623  ...          26.40           166.10      2027.0   \n",
      "565                 0.05533  ...          38.25           155.00      1731.0   \n",
      "566                 0.05648  ...          34.12           126.70      1124.0   \n",
      "567                 0.07016  ...          39.42           184.60      1821.0   \n",
      "568                 0.05884  ...          30.37            59.16       268.6   \n",
      "\n",
      "     worst smoothness  worst compactness  worst concavity  \\\n",
      "0             0.16220            0.66560           0.7119   \n",
      "1             0.12380            0.18660           0.2416   \n",
      "2             0.14440            0.42450           0.4504   \n",
      "3             0.20980            0.86630           0.6869   \n",
      "4             0.13740            0.20500           0.4000   \n",
      "..                ...                ...              ...   \n",
      "564           0.14100            0.21130           0.4107   \n",
      "565           0.11660            0.19220           0.3215   \n",
      "566           0.11390            0.30940           0.3403   \n",
      "567           0.16500            0.86810           0.9387   \n",
      "568           0.08996            0.06444           0.0000   \n",
      "\n",
      "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
      "0                  0.2654          0.4601                  0.11890      0  \n",
      "1                  0.1860          0.2750                  0.08902      0  \n",
      "2                  0.2430          0.3613                  0.08758      0  \n",
      "3                  0.2575          0.6638                  0.17300      0  \n",
      "4                  0.1625          0.2364                  0.07678      0  \n",
      "..                    ...             ...                      ...    ...  \n",
      "564                0.2216          0.2060                  0.07115      0  \n",
      "565                0.1628          0.2572                  0.06637      0  \n",
      "566                0.1418          0.2218                  0.07820      0  \n",
      "567                0.2650          0.4087                  0.12400      0  \n",
      "568                0.0000          0.2871                  0.07039      1  \n",
      "\n",
      "[569 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# 시각화\n",
    "data_data = data.data\n",
    "data_label = data.target\n",
    "\n",
    "\n",
    "data_df = pd.DataFrame(data = data_data,\n",
    "                       columns = data.feature_names)\n",
    "\n",
    "data_df[\"label\"] = data.target\n",
    "\n",
    "print(data_data.shape)\n",
    "print(data_label.shape)\n",
    "print(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e25064f",
   "metadata": {},
   "source": [
    "# 5가지의 학습모델 중에서 Logistic Regression 모델이 정확도가 가장 높았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed3283b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 개수:  455 , X_test 개수:  114\n",
      "classifier\n",
      "0.9298245614035088\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91        46\n",
      "           1       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "X_train 개수:  455 , X_test 개수:  114\n",
      "classifier\n",
      "0.9473684210526315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92        41\n",
      "           1       0.95      0.97      0.96        73\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "X_train 개수:  455 , X_test 개수:  114\n",
      "classifier\n",
      "0.8859649122807017\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85        44\n",
      "           1       0.90      0.91      0.91        70\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.88      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "X_train 개수:  455 , X_test 개수:  114\n",
      "classifier\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91        51\n",
      "           1       0.95      0.90      0.93        63\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.92      0.92      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "X_train 개수:  455 , X_test 개수:  114\n",
      "classifier\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89        42\n",
      "           1       0.94      0.93      0.94        72\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.91      0.92      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# 섞기 및 학습\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_data, \n",
    "                                                    data_label, \n",
    "                                                    test_size =0.2, \n",
    "                                                    )\n",
    "\n",
    "    print('X_train 개수: ', len(X_train),', X_test 개수: ', len(X_test))\n",
    "    X_train.shape, y_train.shape # 확인\n",
    "    X_test.shape, y_test.shape  # 확인\n",
    "\n",
    "    decision_tree = DecisionTreeClassifier()\n",
    "    print(decision_tree._estimator_type)\n",
    "\n",
    "    # 학습 \n",
    "    decision_tree.fit(X_train, y_train)\n",
    "\n",
    "    #예측\n",
    "    y_pred = decision_tree.predict(X_test)\n",
    "    y_pred\n",
    "\n",
    "     #정확도\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(accuracy)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f0ef1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9649122807017544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        45\n",
      "           1       0.96      0.99      0.97        69\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n",
      "0.956140350877193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        45\n",
      "           1       0.96      0.97      0.96        69\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "0.956140350877193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        55\n",
      "           1       0.94      0.98      0.96        59\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.96      0.96       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "0.9649122807017544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        38\n",
      "           1       0.99      0.96      0.97        76\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.97      0.96       114\n",
      "weighted avg       0.97      0.96      0.97       114\n",
      "\n",
      "0.956140350877193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        42\n",
      "           1       1.00      0.93      0.96        72\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.95      0.97      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 섞기 및 학습\n",
    "for i in range(5):\n",
    "    X2_train, X2_test, y2_train, y2_test = train_test_split(data_data, \n",
    "                                                    data_label, \n",
    "                                                    test_size=0.2)\n",
    "                                                                                                \n",
    "    random_forest = RandomForestClassifier()\n",
    "    random_forest.fit(X2_train, y2_train)\n",
    "    y2_pred = random_forest.predict(X2_test)\n",
    "\n",
    "    accuracy2 = accuracy_score(y2_test, y2_pred)\n",
    "    print(accuracy2)\n",
    "    print(classification_report(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e67692a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "0.9298245614035088\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.90        46\n",
      "           1       0.89      1.00      0.94        68\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.95      0.91      0.92       114\n",
      "weighted avg       0.94      0.93      0.93       114\n",
      "\n",
      "0.9385964912280702\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.82      0.89        34\n",
      "           1       0.93      0.99      0.96        80\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.91      0.92       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "0.9298245614035088\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90        42\n",
      "           1       0.93      0.96      0.95        72\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.92       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "0.9473684210526315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92        39\n",
      "           1       0.95      0.97      0.96        75\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.82      0.88        39\n",
      "           1       0.91      0.97      0.94        75\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# svm 모델\n",
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "print(svm_model._estimator_type)\n",
    "\n",
    "# 섞기 및 학습\n",
    "for i in range(5):\n",
    "    X3_train, X3_test, y3_train, y3_test = train_test_split(data_data, \n",
    "                                                    data_label, \n",
    "                                                    test_size=0.2)\n",
    "                                                                                                \n",
    "    random_forest = RandomForestClassifier()\n",
    "    random_forest.fit(X3_train, y3_train)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y3_pred = svm_model.predict(X3_test)\n",
    "\n",
    "\n",
    "\n",
    "    accuracy3 = accuracy_score(y3_test, y3_pred)\n",
    "    print(accuracy3)\n",
    "    print(classification_report(y3_test, y3_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ba97d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "0.4649122807017544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.47      0.44        51\n",
      "           1       0.52      0.46      0.49        63\n",
      "\n",
      "    accuracy                           0.46       114\n",
      "   macro avg       0.47      0.47      0.46       114\n",
      "weighted avg       0.47      0.46      0.47       114\n",
      "\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.45      0.47        38\n",
      "           1       0.74      0.78      0.76        76\n",
      "\n",
      "    accuracy                           0.67       114\n",
      "   macro avg       0.62      0.61      0.61       114\n",
      "weighted avg       0.66      0.67      0.66       114\n",
      "\n",
      "0.5614035087719298\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.33      0.39        49\n",
      "           1       0.59      0.74      0.66        65\n",
      "\n",
      "    accuracy                           0.56       114\n",
      "   macro avg       0.54      0.53      0.52       114\n",
      "weighted avg       0.55      0.56      0.54       114\n",
      "\n",
      "0.5789473684210527\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.23      0.31        47\n",
      "           1       0.60      0.82      0.70        67\n",
      "\n",
      "    accuracy                           0.58       114\n",
      "   macro avg       0.54      0.53      0.51       114\n",
      "weighted avg       0.55      0.58      0.54       114\n",
      "\n",
      "0.543859649122807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.23      0.28        43\n",
      "           1       0.61      0.73      0.67        71\n",
      "\n",
      "    accuracy                           0.54       114\n",
      "   macro avg       0.48      0.48      0.47       114\n",
      "weighted avg       0.51      0.54      0.52       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SGD Classifier 모델\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "print(sgd_model._estimator_type)\n",
    "\n",
    "\n",
    "# 섞기 및 학습\n",
    "for i in range(5):\n",
    "    X4_train, X4_test, y4_train, y4_test = train_test_split(data_data, \n",
    "                                                    data_label, \n",
    "                                                    test_size=0.2)\n",
    "                                                                                                \n",
    "    \n",
    "    sgd_model.fit(X4_train, y4_train)\n",
    "    y4_pred = sgd_model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "    accuracy4 = accuracy_score(y4_test, y4_pred)\n",
    "    print(accuracy4)\n",
    "    print(classification_report(y4_test, y4_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a117c13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "0.9736842105263158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        35\n",
      "           1       1.00      0.96      0.98        79\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.96      0.98      0.97       114\n",
      "weighted avg       0.98      0.97      0.97       114\n",
      "\n",
      "0.9736842105263158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        35\n",
      "           1       1.00      0.96      0.98        79\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.96      0.98      0.97       114\n",
      "weighted avg       0.98      0.97      0.97       114\n",
      "\n",
      "0.9736842105263158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        35\n",
      "           1       1.00      0.96      0.98        79\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.96      0.98      0.97       114\n",
      "weighted avg       0.98      0.97      0.97       114\n",
      "\n",
      "0.9736842105263158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        35\n",
      "           1       1.00      0.96      0.98        79\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.96      0.98      0.97       114\n",
      "weighted avg       0.98      0.97      0.97       114\n",
      "\n",
      "0.9736842105263158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        35\n",
      "           1       1.00      0.96      0.98        79\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.96      0.98      0.97       114\n",
      "weighted avg       0.98      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression 모델\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression(max_iter=3000)\n",
    "# https://url.kr/aqxgue에서 max_iter=(3000)를 알게됨\n",
    "\n",
    "print(logistic_model._estimator_type)\n",
    "\n",
    "\n",
    "# 섞기 및 학습\n",
    "\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(data_data, \n",
    "                                                    data_label, \n",
    "                                                    test_size=0.2)\n",
    "                                                                                                \n",
    "for i in range(5):  # 계산하는데 시간이 어느정도 걸린다.\n",
    "    logistic_model.fit(X5_train, y5_train)\n",
    "    y5_pred = logistic_model.predict(X5_test)\n",
    "\n",
    "    accuracy5 = accuracy_score(y5_test, y5_pred)\n",
    "    print(accuracy5)\n",
    "    print(classification_report(y5_test, y5_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452ac538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
