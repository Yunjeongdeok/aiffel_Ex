{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d808218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345d20e5",
   "metadata": {},
   "source": [
    "학습을 할 때 여러번 눌러서 결과를 확인해야했다. 좀 더 편하게 하기위해 반복문을 썼으나 실패했다. 반복할 때마다 tain과 test도 변해야하지만 실패했다. 여러가지 random을 써보았으나 방법을 찾지 못했다. \n",
    "\n",
    "각각 10번씩 해보니 svm의 정확도가 가장 높이 나왔다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df61e998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "<class 'sklearn.utils.Bunch'>\n",
      "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://url.kr/ye8q3o를 참조함.\n",
    "\n",
    "digits = load_digits()\n",
    "print(digits.data.shape) #총 1791개의 이미지가 있고 8x8로 이루어졌다.\n",
    "print(type(digits))\n",
    "print(digits.keys()) #data', 'target', 'frame', 'feature_names', 'target_names', 'images'이 있다.\n",
    "\n",
    "\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[1780]) #그 중 1780번째의 이미지를 확인\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a0b1d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0           0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1           0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2           0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3           0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4           0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        0.0        4.0       10.0       13.0        6.0   \n",
       "1793        0.0        0.0        6.0       16.0       13.0       11.0   \n",
       "1794        0.0        0.0        1.0       11.0       15.0        1.0   \n",
       "1795        0.0        0.0        2.0       10.0        7.0        0.0   \n",
       "1796        0.0        0.0       10.0       14.0        8.0        1.0   \n",
       "\n",
       "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
       "0           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "3           0.0        0.0        0.0        8.0  ...        0.0        0.0   \n",
       "4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "1792        0.0        0.0        0.0        1.0  ...        0.0        0.0   \n",
       "1793        1.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1794        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1795        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1796        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
       "\n",
       "      pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
       "0           0.0        6.0       13.0       10.0        0.0        0.0   \n",
       "1           0.0        0.0       11.0       16.0       10.0        0.0   \n",
       "2           0.0        0.0        3.0       11.0       16.0        9.0   \n",
       "3           0.0        7.0       13.0       13.0        9.0        0.0   \n",
       "4           0.0        0.0        2.0       16.0        4.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        2.0       14.0       15.0        9.0        0.0   \n",
       "1793        0.0        6.0       16.0       14.0        6.0        0.0   \n",
       "1794        0.0        2.0        9.0       13.0        6.0        0.0   \n",
       "1795        0.0        5.0       12.0       16.0       12.0        0.0   \n",
       "1796        1.0        8.0       12.0       14.0       12.0        1.0   \n",
       "\n",
       "      pixel_7_7  label  \n",
       "0           0.0      0  \n",
       "1           0.0      1  \n",
       "2           0.0      2  \n",
       "3           0.0      3  \n",
       "4           0.0      4  \n",
       "...         ...    ...  \n",
       "1792        0.0      9  \n",
       "1793        0.0      0  \n",
       "1794        0.0      8  \n",
       "1795        0.0      9  \n",
       "1796        0.0      8  \n",
       "\n",
       "[1797 rows x 65 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시각화\n",
    "digits_data = digits.data  # feature_data 지정\n",
    "digits_label = digits.target # Label Data 지정\n",
    "\n",
    "print(digits.target.shape) \n",
    "print(digits.target_names) #Target Names 출력해 보기, 9개의 답.\n",
    "\n",
    "digits_df = pd.DataFrame(data=digits_data,\n",
    "                         columns=digits.feature_names)\n",
    "digits_df[\"label\"] = digits.target # 이것으로 0~9를 분류할 수 있다.\n",
    "\n",
    "digits_df\n",
    "\n",
    "# 앞서 1797의 이미지가 있고 이 이미지는 8X8이란 걸 알았고 표로 작성하였다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7c9c37",
   "metadata": {},
   "source": [
    "# 5가지의 학습 모델 중 SVM이 가장 정확도가 높았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff8f10b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 개수:  1437 , X_test 개수:  360\n",
      "classifier\n",
      "0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        39\n",
      "           1       0.84      0.76      0.80        50\n",
      "           2       0.84      0.87      0.86        31\n",
      "           3       0.93      0.85      0.89        33\n",
      "           4       0.88      0.88      0.88        42\n",
      "           5       0.76      0.85      0.80        33\n",
      "           6       0.95      0.95      0.95        40\n",
      "           7       0.82      0.87      0.84        31\n",
      "           8       0.70      0.72      0.71        32\n",
      "           9       0.73      0.76      0.75        29\n",
      "\n",
      "    accuracy                           0.85       360\n",
      "   macro avg       0.85      0.85      0.85       360\n",
      "weighted avg       0.85      0.85      0.85       360\n",
      "\n",
      "X_train 개수:  1437 , X_test 개수:  360\n",
      "classifier\n",
      "0.8361111111111111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        42\n",
      "           1       0.67      0.76      0.71        41\n",
      "           2       0.85      0.74      0.79        31\n",
      "           3       0.89      0.91      0.90        34\n",
      "           4       0.89      0.82      0.85        39\n",
      "           5       0.89      0.85      0.87        40\n",
      "           6       0.77      0.87      0.82        31\n",
      "           7       0.91      0.94      0.92        31\n",
      "           8       0.74      0.81      0.77        36\n",
      "           9       0.79      0.74      0.76        35\n",
      "\n",
      "    accuracy                           0.84       360\n",
      "   macro avg       0.84      0.84      0.84       360\n",
      "weighted avg       0.84      0.84      0.84       360\n",
      "\n",
      "X_train 개수:  1437 , X_test 개수:  360\n",
      "classifier\n",
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        39\n",
      "           1       0.63      0.81      0.71        32\n",
      "           2       0.86      0.67      0.75        36\n",
      "           3       0.72      0.82      0.77        38\n",
      "           4       0.88      0.83      0.86        36\n",
      "           5       0.95      1.00      0.97        39\n",
      "           6       0.90      0.95      0.92        37\n",
      "           7       0.85      0.80      0.82        35\n",
      "           8       0.64      0.67      0.65        27\n",
      "           9       0.89      0.76      0.82        41\n",
      "\n",
      "    accuracy                           0.83       360\n",
      "   macro avg       0.83      0.83      0.83       360\n",
      "weighted avg       0.84      0.83      0.83       360\n",
      "\n",
      "X_train 개수:  1437 , X_test 개수:  360\n",
      "classifier\n",
      "0.8611111111111112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91        34\n",
      "           1       0.78      0.88      0.82        32\n",
      "           2       0.86      0.91      0.89        34\n",
      "           3       0.74      0.88      0.81        26\n",
      "           4       0.74      0.72      0.73        32\n",
      "           5       0.87      0.87      0.87        31\n",
      "           6       0.93      0.91      0.92        46\n",
      "           7       0.93      0.93      0.93        40\n",
      "           8       0.84      0.79      0.82        34\n",
      "           9       0.95      0.78      0.86        51\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.85      0.86      0.86       360\n",
      "weighted avg       0.87      0.86      0.86       360\n",
      "\n",
      "X_train 개수:  1437 , X_test 개수:  360\n",
      "classifier\n",
      "0.8583333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        44\n",
      "           1       0.85      0.90      0.88        39\n",
      "           2       0.74      0.89      0.81        28\n",
      "           3       0.89      0.87      0.88        38\n",
      "           4       0.84      0.84      0.84        32\n",
      "           5       0.80      0.97      0.88        34\n",
      "           6       0.97      0.86      0.91        42\n",
      "           7       0.96      0.90      0.93        30\n",
      "           8       0.81      0.65      0.72        46\n",
      "           9       0.71      0.74      0.73        27\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.85      0.86      0.85       360\n",
      "weighted avg       0.86      0.86      0.86       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# 섞기 및 학습\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(digits_data, \n",
    "                                                    digits_label, \n",
    "                                                    test_size =0.2, \n",
    "                                                    )\n",
    "\n",
    "    print('X_train 개수: ', len(X_train),', X_test 개수: ', len(X_test))\n",
    "    X_train.shape, y_train.shape # 확인\n",
    "    X_test.shape, y_test.shape  # 확인\n",
    "\n",
    "    decision_tree = DecisionTreeClassifier()\n",
    "    print(decision_tree._estimator_type)\n",
    "\n",
    "    # 학습 \n",
    "    decision_tree.fit(X_train, y_train)\n",
    "\n",
    "    #예측\n",
    "    y_pred = decision_tree.predict(X_test)\n",
    "    y_pred\n",
    "\n",
    "     #정확도\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(accuracy)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4664bee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        31\n",
      "           1       0.91      1.00      0.95        42\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       0.94      0.97      0.96        35\n",
      "           4       0.98      1.00      0.99        40\n",
      "           5       0.94      0.97      0.96        35\n",
      "           6       1.00      0.97      0.98        33\n",
      "           7       0.96      1.00      0.98        45\n",
      "           8       0.97      0.86      0.91        36\n",
      "           9       1.00      0.90      0.95        30\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.96      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "0.9666666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        41\n",
      "           1       0.94      1.00      0.97        33\n",
      "           2       1.00      0.95      0.97        37\n",
      "           3       0.97      0.95      0.96        40\n",
      "           4       1.00      0.96      0.98        28\n",
      "           5       0.97      0.97      0.97        35\n",
      "           6       0.97      0.97      0.97        36\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.88      0.93      0.90        30\n",
      "           9       1.00      0.95      0.97        41\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "0.9722222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        41\n",
      "           1       1.00      1.00      1.00        33\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.97      0.95      0.96        37\n",
      "           4       0.96      0.96      0.96        24\n",
      "           5       1.00      0.97      0.99        39\n",
      "           6       1.00      0.97      0.99        35\n",
      "           7       0.88      1.00      0.94        36\n",
      "           8       0.97      0.90      0.93        31\n",
      "           9       1.00      0.95      0.98        44\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "0.9694444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        33\n",
      "           1       0.97      1.00      0.98        31\n",
      "           2       1.00      0.96      0.98        28\n",
      "           3       1.00      0.89      0.94        37\n",
      "           4       0.98      0.98      0.98        48\n",
      "           5       0.94      1.00      0.97        34\n",
      "           6       1.00      0.98      0.99        41\n",
      "           7       0.97      0.97      0.97        32\n",
      "           8       0.89      0.97      0.93        34\n",
      "           9       0.98      0.98      0.98        42\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "0.9722222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       0.96      1.00      0.98        43\n",
      "           2       1.00      1.00      1.00        30\n",
      "           3       0.97      0.97      0.97        33\n",
      "           4       1.00      0.97      0.99        39\n",
      "           5       0.92      0.94      0.93        35\n",
      "           6       1.00      0.97      0.99        35\n",
      "           7       0.97      1.00      0.99        33\n",
      "           8       0.97      0.93      0.95        40\n",
      "           9       0.95      0.95      0.95        39\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 섞기 및 학습\n",
    "for i in range(5):\n",
    "    X2_train, X2_test, y2_train, y2_test = train_test_split(digits_data, \n",
    "                                                    digits_label, \n",
    "                                                    test_size=0.2)\n",
    "                                                                                                \n",
    "    random_forest = RandomForestClassifier()\n",
    "    random_forest.fit(X2_train, y2_train)\n",
    "    y2_pred = random_forest.predict(X2_test)\n",
    "\n",
    "    accuracy2 = accuracy_score(y2_test, y2_pred)\n",
    "    print(accuracy2)\n",
    "    print(classification_report(y2_test, y2_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2b04e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "0.9944444444444445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       1.00      1.00      1.00        34\n",
      "           2       1.00      1.00      1.00        36\n",
      "           3       1.00      0.98      0.99        42\n",
      "           4       1.00      1.00      1.00        40\n",
      "           5       0.96      1.00      0.98        44\n",
      "           6       1.00      1.00      1.00        36\n",
      "           7       1.00      1.00      1.00        29\n",
      "           8       1.00      1.00      1.00        31\n",
      "           9       1.00      0.97      0.99        36\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       1.00      0.99      1.00       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "0.9916666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        28\n",
      "           1       0.98      1.00      0.99        41\n",
      "           2       1.00      1.00      1.00        36\n",
      "           3       0.98      1.00      0.99        40\n",
      "           4       1.00      1.00      1.00        27\n",
      "           5       1.00      0.97      0.99        34\n",
      "           6       1.00      1.00      1.00        41\n",
      "           7       1.00      1.00      1.00        39\n",
      "           8       1.00      0.97      0.99        39\n",
      "           9       0.97      0.97      0.97        35\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "0.9944444444444445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        31\n",
      "           1       0.97      1.00      0.99        35\n",
      "           2       1.00      1.00      1.00        37\n",
      "           3       1.00      1.00      1.00        33\n",
      "           4       1.00      1.00      1.00        35\n",
      "           5       1.00      0.97      0.99        36\n",
      "           6       1.00      1.00      1.00        45\n",
      "           7       1.00      1.00      1.00        30\n",
      "           8       1.00      0.98      0.99        41\n",
      "           9       0.97      1.00      0.99        37\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "0.9972222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       1.00      1.00      1.00        46\n",
      "           2       1.00      1.00      1.00        36\n",
      "           3       1.00      1.00      1.00        30\n",
      "           4       1.00      1.00      1.00        40\n",
      "           5       1.00      0.97      0.98        33\n",
      "           6       1.00      1.00      1.00        32\n",
      "           7       1.00      1.00      1.00        30\n",
      "           8       1.00      1.00      1.00        34\n",
      "           9       0.98      1.00      0.99        44\n",
      "\n",
      "    accuracy                           1.00       360\n",
      "   macro avg       1.00      1.00      1.00       360\n",
      "weighted avg       1.00      1.00      1.00       360\n",
      "\n",
      "0.9916666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.95      1.00      0.97        35\n",
      "           2       1.00      1.00      1.00        36\n",
      "           3       1.00      1.00      1.00        32\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       1.00      1.00      1.00        41\n",
      "           6       1.00      1.00      1.00        30\n",
      "           7       1.00      0.97      0.99        35\n",
      "           8       1.00      0.95      0.98        43\n",
      "           9       0.97      1.00      0.99        39\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# svm 모델\n",
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "print(svm_model._estimator_type)\n",
    "\n",
    "# 섞기 및 학습\n",
    "for i in range(5):\n",
    "    X3_train, X3_test, y3_train, y3_test = train_test_split(digits_data, \n",
    "                                                    digits_label, \n",
    "                                                    test_size=0.2)\n",
    "                                                                                                \n",
    "    random_forest = RandomForestClassifier()\n",
    "    random_forest.fit(X3_train, y3_train)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y3_pred = svm_model.predict(X3_test)\n",
    "\n",
    "\n",
    "\n",
    "    accuracy3 = accuracy_score(y3_test, y3_pred)\n",
    "    print(accuracy3)\n",
    "    print(classification_report(y3_test, y3_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e66412e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "0.10555555555555556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.11      0.11        44\n",
      "           1       0.08      0.07      0.08        42\n",
      "           2       0.14      0.11      0.12        36\n",
      "           3       0.08      0.09      0.08        34\n",
      "           4       0.12      0.12      0.12        33\n",
      "           5       0.12      0.10      0.11        40\n",
      "           6       0.02      0.04      0.03        27\n",
      "           7       0.18      0.15      0.17        39\n",
      "           8       0.15      0.23      0.18        31\n",
      "           9       0.04      0.03      0.03        34\n",
      "\n",
      "    accuracy                           0.11       360\n",
      "   macro avg       0.11      0.11      0.10       360\n",
      "weighted avg       0.11      0.11      0.11       360\n",
      "\n",
      "0.09722222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.05      0.05        39\n",
      "           1       0.09      0.12      0.10        34\n",
      "           2       0.10      0.08      0.09        36\n",
      "           3       0.14      0.15      0.14        33\n",
      "           4       0.12      0.10      0.11        39\n",
      "           5       0.06      0.06      0.06        32\n",
      "           6       0.07      0.10      0.08        31\n",
      "           7       0.11      0.07      0.08        46\n",
      "           8       0.14      0.16      0.15        37\n",
      "           9       0.11      0.09      0.10        33\n",
      "\n",
      "    accuracy                           0.10       360\n",
      "   macro avg       0.10      0.10      0.10       360\n",
      "weighted avg       0.10      0.10      0.10       360\n",
      "\n",
      "0.1111111111111111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.14      0.14        42\n",
      "           1       0.18      0.16      0.17        43\n",
      "           2       0.17      0.13      0.15        38\n",
      "           3       0.06      0.05      0.05        41\n",
      "           4       0.19      0.15      0.17        39\n",
      "           5       0.03      0.04      0.04        28\n",
      "           6       0.05      0.06      0.05        36\n",
      "           7       0.10      0.10      0.10        30\n",
      "           8       0.11      0.16      0.13        31\n",
      "           9       0.08      0.09      0.09        32\n",
      "\n",
      "    accuracy                           0.11       360\n",
      "   macro avg       0.11      0.11      0.11       360\n",
      "weighted avg       0.12      0.11      0.11       360\n",
      "\n",
      "0.08611111111111111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.08      0.07        39\n",
      "           1       0.00      0.00      0.00        35\n",
      "           2       0.04      0.02      0.03        44\n",
      "           3       0.11      0.13      0.12        30\n",
      "           4       0.09      0.09      0.09        34\n",
      "           5       0.06      0.07      0.06        30\n",
      "           6       0.12      0.14      0.13        37\n",
      "           7       0.13      0.09      0.11        44\n",
      "           8       0.15      0.24      0.18        29\n",
      "           9       0.08      0.05      0.06        38\n",
      "\n",
      "    accuracy                           0.09       360\n",
      "   macro avg       0.08      0.09      0.09       360\n",
      "weighted avg       0.08      0.09      0.08       360\n",
      "\n",
      "0.09166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.16      0.13        31\n",
      "           1       0.21      0.17      0.19        47\n",
      "           2       0.07      0.05      0.06        41\n",
      "           3       0.06      0.05      0.05        39\n",
      "           4       0.06      0.06      0.06        32\n",
      "           5       0.08      0.10      0.09        29\n",
      "           6       0.15      0.24      0.19        29\n",
      "           7       0.04      0.03      0.03        37\n",
      "           8       0.04      0.06      0.05        35\n",
      "           9       0.04      0.03      0.03        40\n",
      "\n",
      "    accuracy                           0.09       360\n",
      "   macro avg       0.09      0.09      0.09       360\n",
      "weighted avg       0.09      0.09      0.09       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#SGD Classifier 모델\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "print(sgd_model._estimator_type)\n",
    "\n",
    "\n",
    "# 섞기 및 학습\n",
    "for i in range(5):\n",
    "    X4_train, X4_test, y4_train, y4_test = train_test_split(digits_data, \n",
    "                                                    digits_label, \n",
    "                                                    test_size=0.2)\n",
    "                                                                                                \n",
    "    \n",
    "    sgd_model.fit(X4_train, y4_train)\n",
    "    y4_pred = sgd_model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "    accuracy4 = accuracy_score(y4_test, y4_pred)\n",
    "    print(accuracy4)\n",
    "    print(classification_report(y4_test, y4_pred))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bd94185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "0.9916666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00        44\n",
      "           2       1.00      1.00      1.00        38\n",
      "           3       1.00      1.00      1.00        30\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.97      1.00      0.99        37\n",
      "           6       1.00      1.00      1.00        42\n",
      "           7       1.00      0.97      0.99        36\n",
      "           8       0.97      0.97      0.97        29\n",
      "           9       0.97      0.97      0.97        37\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "0.9916666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00        44\n",
      "           2       1.00      1.00      1.00        38\n",
      "           3       1.00      1.00      1.00        30\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.97      1.00      0.99        37\n",
      "           6       1.00      1.00      1.00        42\n",
      "           7       1.00      0.97      0.99        36\n",
      "           8       0.97      0.97      0.97        29\n",
      "           9       0.97      0.97      0.97        37\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "0.9916666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00        44\n",
      "           2       1.00      1.00      1.00        38\n",
      "           3       1.00      1.00      1.00        30\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.97      1.00      0.99        37\n",
      "           6       1.00      1.00      1.00        42\n",
      "           7       1.00      0.97      0.99        36\n",
      "           8       0.97      0.97      0.97        29\n",
      "           9       0.97      0.97      0.97        37\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "0.9916666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00        44\n",
      "           2       1.00      1.00      1.00        38\n",
      "           3       1.00      1.00      1.00        30\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.97      1.00      0.99        37\n",
      "           6       1.00      1.00      1.00        42\n",
      "           7       1.00      0.97      0.99        36\n",
      "           8       0.97      0.97      0.97        29\n",
      "           9       0.97      0.97      0.97        37\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "0.9916666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00        44\n",
      "           2       1.00      1.00      1.00        38\n",
      "           3       1.00      1.00      1.00        30\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.97      1.00      0.99        37\n",
      "           6       1.00      1.00      1.00        42\n",
      "           7       1.00      0.97      0.99        36\n",
      "           8       0.97      0.97      0.97        29\n",
      "           9       0.97      0.97      0.97        37\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression 모델\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression(max_iter=3000)\n",
    "# https://url.kr/aqxgue에서 max_iter=(3000)를 알게됨\n",
    "\n",
    "print(logistic_model._estimator_type)\n",
    "\n",
    "\n",
    "# 섞기 및 학습\n",
    "\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(digits_data, \n",
    "                                                    digits_label, \n",
    "                                                    test_size=0.2)\n",
    "                                                                                                \n",
    "for i in range(5):  # 계산하는데 시간이 어느정도 걸린다.\n",
    "    logistic_model.fit(X_train, y_train)\n",
    "    y5_pred = logistic_model.predict(X5_test)\n",
    "\n",
    "    accuracy5 = accuracy_score(y5_test, y5_pred)\n",
    "    print(accuracy5)\n",
    "    print(classification_report(y5_test, y5_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
