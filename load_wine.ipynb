{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f465d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56594f79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<class 'sklearn.utils.Bunch'>\n",
      "딕션너리 키:  dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])\n",
      "\n",
      "\n",
      "데이터: (178, 13)\n",
      "\n",
      "\n",
      "윤곽:  None\n",
      "\n",
      "\n",
      "문제지 이름(항목):  ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "\n",
      "\n",
      "정답지 이름(카테고리):  ['class_0' 'class_1' 'class_2']\n",
      "\n",
      "\n",
      "정답지 번호(일련번호):  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://url.kr/3t2y1f 참조.\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine(); print('\\n')\n",
    "\n",
    "print(type(wine))\n",
    "\n",
    "print('딕션너리 키: ', wine.keys()); print('\\n') # 항목을 확인함.\n",
    "\n",
    "print('데이터:', wine.data.shape); print('\\n')\n",
    "print('윤곽: ', wine.frame); print('\\n')\n",
    "print('문제지 이름(항목): ', wine.feature_names); print('\\n')\n",
    "print('정답지 이름(카테고리): ', wine.target_names); print('\\n')\n",
    "print('정답지 번호(일련번호): ', wine.target); print('\\n')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0826e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n",
      "(178,)\n",
      "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
      "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
      "..       ...         ...   ...                ...        ...            ...   \n",
      "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
      "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
      "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
      "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
      "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
      "\n",
      "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0          3.06                  0.28             2.29             5.64  1.04   \n",
      "1          2.76                  0.26             1.28             4.38  1.05   \n",
      "2          3.24                  0.30             2.81             5.68  1.03   \n",
      "3          3.49                  0.24             2.18             7.80  0.86   \n",
      "4          2.69                  0.39             1.82             4.32  1.04   \n",
      "..          ...                   ...              ...              ...   ...   \n",
      "173        0.61                  0.52             1.06             7.70  0.64   \n",
      "174        0.75                  0.43             1.41             7.30  0.70   \n",
      "175        0.69                  0.43             1.35            10.20  0.59   \n",
      "176        0.68                  0.53             1.46             9.30  0.60   \n",
      "177        0.76                  0.56             1.35             9.20  0.61   \n",
      "\n",
      "     od280/od315_of_diluted_wines  proline  label  \n",
      "0                            3.92   1065.0      0  \n",
      "1                            3.40   1050.0      0  \n",
      "2                            3.17   1185.0      0  \n",
      "3                            3.45   1480.0      0  \n",
      "4                            2.93    735.0      0  \n",
      "..                            ...      ...    ...  \n",
      "173                          1.74    740.0      2  \n",
      "174                          1.56    750.0      2  \n",
      "175                          1.56    835.0      2  \n",
      "176                          1.62    840.0      2  \n",
      "177                          1.60    560.0      2  \n",
      "\n",
      "[178 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# 시각화\n",
    "\n",
    "wine_data = wine.data\n",
    "wine_label = wine.target\n",
    "\n",
    "\n",
    "wine_df = pd.DataFrame(data = wine_data,\n",
    "                       columns = wine.feature_names)\n",
    "\n",
    "wine_df[\"label\"] = wine.target\n",
    "\n",
    "print(wine_data.shape)\n",
    "print(wine_label.shape)\n",
    "print(wine_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5c9e18",
   "metadata": {},
   "source": [
    "# 5가지의  학습모델 중 RandomForestClassifier의 정확도가 가장 컸다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57f4065e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 개수:  142 , X_test 개수:  36\n",
      "classifier\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       0.95      0.90      0.92        20\n",
      "           2       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.90      0.91      0.90        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      "\n",
      "X_train 개수:  142 , X_test 개수:  36\n",
      "classifier\n",
      "0.9444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       1.00      0.88      0.93        16\n",
      "           2       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.94      0.96      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "X_train 개수:  142 , X_test 개수:  36\n",
      "classifier\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93        16\n",
      "           1       0.87      0.93      0.90        14\n",
      "           2       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.91      0.93      0.92        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      "\n",
      "X_train 개수:  142 , X_test 개수:  36\n",
      "classifier\n",
      "0.9444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        16\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.94      0.95      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "X_train 개수:  142 , X_test 개수:  36\n",
      "classifier\n",
      "0.7777777777777778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.82         9\n",
      "           1       0.90      0.56      0.69        16\n",
      "           2       0.77      0.91      0.83        11\n",
      "\n",
      "    accuracy                           0.78        36\n",
      "   macro avg       0.79      0.82      0.78        36\n",
      "weighted avg       0.81      0.78      0.77        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# 섞기 및 학습\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(wine_data, \n",
    "                                                    wine_label, \n",
    "                                                    test_size =0.2, \n",
    "                                                    )\n",
    "\n",
    "    print('X_train 개수: ', len(X_train),', X_test 개수: ', len(X_test))\n",
    "    X_train.shape, y_train.shape # 확인\n",
    "    X_test.shape, y_test.shape  # 확인\n",
    "\n",
    "    decision_tree = DecisionTreeClassifier()\n",
    "    print(decision_tree._estimator_type)\n",
    "\n",
    "    # 학습 \n",
    "    decision_tree.fit(X_train, y_train)\n",
    "\n",
    "    #예측\n",
    "    y_pred = decision_tree.predict(X_test)\n",
    "    y_pred\n",
    "\n",
    "     #정확도\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(accuracy)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcaef100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      0.88      0.94        17\n",
      "           2       0.71      1.00      0.83         5\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.90      0.96      0.92        36\n",
      "weighted avg       0.96      0.94      0.95        36\n",
      "\n",
      "0.9444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97        15\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.94      0.94      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00        15\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "0.9722222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      0.94      0.97        17\n",
      "           2       0.92      1.00      0.96        12\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.97      0.98      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      0.81      0.90        16\n",
      "           2       0.70      1.00      0.82         7\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.90      0.94      0.91        36\n",
      "weighted avg       0.94      0.92      0.92        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 섞기 및 학습\n",
    "for i in range(5):\n",
    "    X2_train, X2_test, y2_train, y2_test = train_test_split(wine_data, \n",
    "                                                    wine_label, \n",
    "                                                    test_size=0.2)\n",
    "                                                                                                \n",
    "    random_forest = RandomForestClassifier()\n",
    "    random_forest.fit(X2_train, y2_train)\n",
    "    y2_pred = random_forest.predict(X2_test)\n",
    "\n",
    "    accuracy2 = accuracy_score(y2_test, y2_pred)\n",
    "    print(accuracy2)\n",
    "    print(classification_report(y2_test, y2_pred))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d6e8e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "0.7222222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       0.54      0.64      0.58        11\n",
      "           2       0.75      0.60      0.67        15\n",
      "\n",
      "    accuracy                           0.72        36\n",
      "   macro avg       0.73      0.75      0.73        36\n",
      "weighted avg       0.73      0.72      0.72        36\n",
      "\n",
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90        15\n",
      "           1       0.71      0.83      0.77        12\n",
      "           2       0.50      0.44      0.47         9\n",
      "\n",
      "    accuracy                           0.75        36\n",
      "   macro avg       0.71      0.71      0.71        36\n",
      "weighted avg       0.75      0.75      0.75        36\n",
      "\n",
      "0.6388888888888888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       0.60      0.71      0.65        17\n",
      "           2       0.29      0.20      0.24        10\n",
      "\n",
      "    accuracy                           0.64        36\n",
      "   macro avg       0.63      0.64      0.63        36\n",
      "weighted avg       0.61      0.64      0.62        36\n",
      "\n",
      "0.7222222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88        12\n",
      "           1       0.59      0.91      0.71        11\n",
      "           2       0.83      0.38      0.53        13\n",
      "\n",
      "    accuracy                           0.72        36\n",
      "   macro avg       0.76      0.74      0.71        36\n",
      "weighted avg       0.76      0.72      0.70        36\n",
      "\n",
      "0.6944444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87        11\n",
      "           1       0.73      0.65      0.69        17\n",
      "           2       0.44      0.50      0.47         8\n",
      "\n",
      "    accuracy                           0.69        36\n",
      "   macro avg       0.67      0.69      0.68        36\n",
      "weighted avg       0.70      0.69      0.69        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# svm 모델\n",
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "print(svm_model._estimator_type)\n",
    "\n",
    "# 섞기 및 학습\n",
    "for i in range(5):\n",
    "    X3_train, X3_test, y3_train, y3_test = train_test_split(wine_data, \n",
    "                                                    wine_label, \n",
    "                                                    test_size=0.2)\n",
    "                                                                                                \n",
    "    random_forest = RandomForestClassifier()\n",
    "    random_forest.fit(X3_train, y3_train)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y3_pred = svm_model.predict(X3_test)\n",
    "\n",
    "\n",
    "\n",
    "    accuracy3 = accuracy_score(y3_test, y3_pred)\n",
    "    print(accuracy3)\n",
    "    print(classification_report(y3_test, y3_pred))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f3bedf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "0.35185185185185186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      1.00      0.57        15\n",
      "           1       0.00      0.00      0.00        24\n",
      "           2       0.25      0.27      0.26        15\n",
      "\n",
      "    accuracy                           0.35        54\n",
      "   macro avg       0.21      0.42      0.27        54\n",
      "weighted avg       0.18      0.35      0.23        54\n",
      "\n",
      "0.5370370370370371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      1.00      0.70        14\n",
      "           1       1.00      0.29      0.44        21\n",
      "           2       0.41      0.47      0.44        19\n",
      "\n",
      "    accuracy                           0.54        54\n",
      "   macro avg       0.65      0.59      0.53        54\n",
      "weighted avg       0.67      0.54      0.51        54\n",
      "\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67        16\n",
      "           1       0.41      1.00      0.58        19\n",
      "           2       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.50        54\n",
      "   macro avg       0.47      0.50      0.42        54\n",
      "weighted avg       0.44      0.50      0.40        54\n",
      "\n",
      "0.42592592592592593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.56      0.71        18\n",
      "           1       0.00      0.00      0.00        23\n",
      "           2       0.30      1.00      0.46        13\n",
      "\n",
      "    accuracy                           0.43        54\n",
      "   macro avg       0.43      0.52      0.39        54\n",
      "weighted avg       0.40      0.43      0.35        54\n",
      "\n",
      "0.6111111111111112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.83        19\n",
      "           1       0.75      0.15      0.25        20\n",
      "           2       0.46      0.87      0.60        15\n",
      "\n",
      "    accuracy                           0.61        54\n",
      "   macro avg       0.66      0.64      0.56        54\n",
      "weighted avg       0.68      0.61      0.55        54\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SGD Classifier 모델\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "print(sgd_model._estimator_type)\n",
    "\n",
    "\n",
    "# 섞기 및 학습\n",
    "for i in range(5):\n",
    "    X4_train, X4_test, y4_train, y4_test = train_test_split(wine_data, \n",
    "                                                    wine_label, \n",
    "                                                    test_size=0.3)\n",
    "                                                                                                \n",
    "    \n",
    "    sgd_model.fit(X4_train, y4_train)\n",
    "    y4_pred = sgd_model.predict(X4_test)\n",
    "\n",
    "\n",
    "\n",
    "    accuracy4 = accuracy_score(y4_test, y4_pred)\n",
    "    print(accuracy4)\n",
    "    print(classification_report(y4_test, y4_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a229ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "0.9444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        14\n",
      "           1       0.94      0.94      0.94        16\n",
      "           2       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.92      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "0.9444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        14\n",
      "           1       0.94      0.94      0.94        16\n",
      "           2       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.92      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "0.9444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        14\n",
      "           1       0.94      0.94      0.94        16\n",
      "           2       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.92      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "0.9444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        14\n",
      "           1       0.94      0.94      0.94        16\n",
      "           2       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.92      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "0.9444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        14\n",
      "           1       0.94      0.94      0.94        16\n",
      "           2       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.92      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression 모델\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression(max_iter=3000)\n",
    "# https://url.kr/aqxgue에서 max_iter=(3000)를 알게됨\n",
    "\n",
    "print(logistic_model._estimator_type)\n",
    "\n",
    "\n",
    "# 섞기 및 학습\n",
    "\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(wine_data, \n",
    "                                                    wine_label, \n",
    "                                                    test_size=0.2)\n",
    "                                                                                                \n",
    "for i in range(5):  # 계산하는데 시간이 어느정도 걸린다.\n",
    "    logistic_model.fit(X5_train, y5_train)\n",
    "    y5_pred = logistic_model.predict(X5_test)\n",
    "\n",
    "    accuracy5 = accuracy_score(y5_test, y5_pred)\n",
    "    print(accuracy5)\n",
    "    print(classification_report(y5_test, y5_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dcd95a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
