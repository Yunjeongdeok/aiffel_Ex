{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80a7b60a",
   "metadata": {},
   "source": [
    "# load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d808218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345d20e5",
   "metadata": {},
   "source": [
    "학습을 할 때 여러번 눌러서 결과를 확인해야했다. 좀 더 편하게 하기위해 반복문을 썼으나 실패했다. 반복할 때마다 tain과 test도 변해야하지만 실패했다. 여러가지 random을 써보았으나 방법을 찾지 못했다. \n",
    "\n",
    "각각 10번씩 해보니 svm의 accuracy 정확도가 가장 높이 나왔다.  따라서 svm의 정혹도가 가장 높다고 생각한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df61e998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "<class 'sklearn.utils.Bunch'>\n",
      "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://url.kr/ye8q3o를 참조함.\n",
    "\n",
    "digits = load_digits()\n",
    "print(digits.data.shape) #총 1791개의 이미지가 있고 8x8로 이루어졌다.\n",
    "print(type(digits))\n",
    "print(digits.keys()) #data', 'target', 'frame', 'feature_names', 'target_names', 'images'이 있다.\n",
    "\n",
    "\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[1780]) #그 중 1780번째의 이미지를 확인\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a0b1d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0           0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1           0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2           0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3           0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4           0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        0.0        4.0       10.0       13.0        6.0   \n",
       "1793        0.0        0.0        6.0       16.0       13.0       11.0   \n",
       "1794        0.0        0.0        1.0       11.0       15.0        1.0   \n",
       "1795        0.0        0.0        2.0       10.0        7.0        0.0   \n",
       "1796        0.0        0.0       10.0       14.0        8.0        1.0   \n",
       "\n",
       "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
       "0           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "3           0.0        0.0        0.0        8.0  ...        0.0        0.0   \n",
       "4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "1792        0.0        0.0        0.0        1.0  ...        0.0        0.0   \n",
       "1793        1.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1794        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1795        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1796        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
       "\n",
       "      pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
       "0           0.0        6.0       13.0       10.0        0.0        0.0   \n",
       "1           0.0        0.0       11.0       16.0       10.0        0.0   \n",
       "2           0.0        0.0        3.0       11.0       16.0        9.0   \n",
       "3           0.0        7.0       13.0       13.0        9.0        0.0   \n",
       "4           0.0        0.0        2.0       16.0        4.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        2.0       14.0       15.0        9.0        0.0   \n",
       "1793        0.0        6.0       16.0       14.0        6.0        0.0   \n",
       "1794        0.0        2.0        9.0       13.0        6.0        0.0   \n",
       "1795        0.0        5.0       12.0       16.0       12.0        0.0   \n",
       "1796        1.0        8.0       12.0       14.0       12.0        1.0   \n",
       "\n",
       "      pixel_7_7  label  \n",
       "0           0.0      0  \n",
       "1           0.0      1  \n",
       "2           0.0      2  \n",
       "3           0.0      3  \n",
       "4           0.0      4  \n",
       "...         ...    ...  \n",
       "1792        0.0      9  \n",
       "1793        0.0      0  \n",
       "1794        0.0      8  \n",
       "1795        0.0      9  \n",
       "1796        0.0      8  \n",
       "\n",
       "[1797 rows x 65 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시각화\n",
    "digits_data = digits.data  # feature_data 지정\n",
    "digits_label = digits.target # Label Data 지정\n",
    "\n",
    "print(digits.target.shape) \n",
    "print(digits.target_names) #Target Names 출력해 보기, 9개의 답.\n",
    "\n",
    "digits_df = pd.DataFrame(data=digits_data,\n",
    "                         columns=digits.feature_names)\n",
    "digits_df[\"label\"] = digits.target # 이것으로 0~9를 분류할 수 있다.\n",
    "\n",
    "digits_df\n",
    "\n",
    "# 앞서 1797의 이미지가 있고 이 이미지는 8X8이란 걸 알았고 표로 작성하였다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7c9c37",
   "metadata": {},
   "source": [
    "# load_digits의 5가지의 학습 모델 중 SVM의 accuracy가 가장 정확도가 높았다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff8f10b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 개수:  1437 , X_test 개수:  360\n",
      "classifier\n",
      "0.8527777777777777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92        44\n",
      "           1       0.68      0.89      0.77        28\n",
      "           2       0.84      0.95      0.89        38\n",
      "           3       0.90      0.74      0.81        38\n",
      "           4       0.80      0.83      0.81        29\n",
      "           5       0.91      0.83      0.87        36\n",
      "           6       1.00      0.91      0.96        47\n",
      "           7       0.90      0.90      0.90        39\n",
      "           8       0.74      0.61      0.67        33\n",
      "           9       0.78      0.89      0.83        28\n",
      "\n",
      "    accuracy                           0.85       360\n",
      "   macro avg       0.85      0.85      0.84       360\n",
      "weighted avg       0.86      0.85      0.85       360\n",
      "\n",
      "X_train 개수:  1437 , X_test 개수:  360\n",
      "classifier\n",
      "0.825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.94        41\n",
      "           1       0.59      0.65      0.62        26\n",
      "           2       0.76      0.91      0.83        35\n",
      "           3       0.77      0.96      0.86        28\n",
      "           4       0.94      0.72      0.82        40\n",
      "           5       0.85      0.85      0.85        34\n",
      "           6       0.87      0.89      0.88        38\n",
      "           7       0.86      0.93      0.89        41\n",
      "           8       0.76      0.57      0.65        44\n",
      "           9       0.83      0.88      0.85        33\n",
      "\n",
      "    accuracy                           0.82       360\n",
      "   macro avg       0.82      0.83      0.82       360\n",
      "weighted avg       0.83      0.82      0.82       360\n",
      "\n",
      "X_train 개수:  1437 , X_test 개수:  360\n",
      "classifier\n",
      "0.8638888888888889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        41\n",
      "           1       0.83      0.81      0.82        37\n",
      "           2       0.90      0.84      0.87        44\n",
      "           3       0.89      0.80      0.85        41\n",
      "           4       0.82      0.91      0.86        35\n",
      "           5       0.81      0.92      0.86        38\n",
      "           6       1.00      0.78      0.88        36\n",
      "           7       0.96      0.93      0.95        28\n",
      "           8       0.66      0.78      0.71        27\n",
      "           9       0.78      0.88      0.83        33\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.87      0.86      0.86       360\n",
      "weighted avg       0.87      0.86      0.87       360\n",
      "\n",
      "X_train 개수:  1437 , X_test 개수:  360\n",
      "classifier\n",
      "0.8583333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        40\n",
      "           1       0.62      0.83      0.71        24\n",
      "           2       0.87      0.92      0.89        37\n",
      "           3       0.83      0.90      0.86        39\n",
      "           4       0.84      0.82      0.83        38\n",
      "           5       0.85      0.83      0.84        35\n",
      "           6       0.97      0.92      0.95        39\n",
      "           7       0.89      0.87      0.88        39\n",
      "           8       0.85      0.66      0.74        35\n",
      "           9       0.80      0.82      0.81        34\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.85      0.85      0.85       360\n",
      "weighted avg       0.86      0.86      0.86       360\n",
      "\n",
      "X_train 개수:  1437 , X_test 개수:  360\n",
      "classifier\n",
      "0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        39\n",
      "           1       0.85      0.87      0.86        38\n",
      "           2       0.80      1.00      0.89        36\n",
      "           3       0.88      0.81      0.84        43\n",
      "           4       0.94      0.82      0.88        40\n",
      "           5       0.91      0.84      0.88        38\n",
      "           6       0.90      0.97      0.93        29\n",
      "           7       0.90      0.87      0.88        30\n",
      "           8       0.79      0.74      0.76        35\n",
      "           9       0.62      0.66      0.64        32\n",
      "\n",
      "    accuracy                           0.85       360\n",
      "   macro avg       0.85      0.85      0.85       360\n",
      "weighted avg       0.85      0.85      0.85       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# 섞기 및 학습\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(digits_data, \n",
    "                                                    digits_label, \n",
    "                                                    test_size =0.2, \n",
    "                                                    )\n",
    "\n",
    "    print('X_train 개수: ', len(X_train),', X_test 개수: ', len(X_test))\n",
    "    X_train.shape, y_train.shape # 확인\n",
    "    X_test.shape, y_test.shape  # 확인\n",
    "\n",
    "    decision_tree = DecisionTreeClassifier()\n",
    "    print(decision_tree._estimator_type)\n",
    "\n",
    "    # 학습 \n",
    "    decision_tree.fit(X_train, y_train)\n",
    "\n",
    "    #예측\n",
    "    y_pred = decision_tree.predict(X_test)\n",
    "    y_pred\n",
    "\n",
    "     #정확도\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(accuracy)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4664bee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9611111111111111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        30\n",
      "           1       0.98      1.00      0.99        45\n",
      "           2       0.97      1.00      0.98        31\n",
      "           3       1.00      0.97      0.99        40\n",
      "           4       0.97      1.00      0.98        30\n",
      "           5       0.92      0.97      0.94        34\n",
      "           6       1.00      1.00      1.00        35\n",
      "           7       0.93      0.97      0.95        39\n",
      "           8       0.95      0.88      0.91        41\n",
      "           9       0.91      0.86      0.88        35\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n",
      "0.9833333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        27\n",
      "           1       0.98      1.00      0.99        41\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       1.00      0.93      0.96        44\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.96      1.00      0.98        25\n",
      "           6       1.00      0.98      0.99        43\n",
      "           7       0.94      0.97      0.96        34\n",
      "           8       1.00      0.97      0.98        30\n",
      "           9       0.97      1.00      0.99        39\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n",
      "0.9694444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        39\n",
      "           1       0.95      1.00      0.97        38\n",
      "           2       1.00      1.00      1.00        32\n",
      "           3       1.00      0.97      0.99        38\n",
      "           4       0.95      1.00      0.97        39\n",
      "           5       0.90      0.93      0.91        28\n",
      "           6       0.97      0.97      0.97        40\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.97      0.89      0.93        37\n",
      "           9       0.96      0.90      0.93        30\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "0.9805555555555555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        34\n",
      "           1       0.97      1.00      0.99        35\n",
      "           2       1.00      1.00      1.00        38\n",
      "           3       1.00      0.97      0.99        38\n",
      "           4       1.00      0.95      0.97        38\n",
      "           5       0.97      0.97      0.97        39\n",
      "           6       0.97      0.94      0.95        32\n",
      "           7       0.93      1.00      0.96        41\n",
      "           8       0.97      0.97      0.97        36\n",
      "           9       1.00      1.00      1.00        29\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n",
      "0.9805555555555555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        29\n",
      "           1       0.95      1.00      0.97        38\n",
      "           2       1.00      1.00      1.00        32\n",
      "           3       0.97      1.00      0.99        39\n",
      "           4       0.97      1.00      0.99        36\n",
      "           5       0.98      0.95      0.97        44\n",
      "           6       1.00      1.00      1.00        25\n",
      "           7       0.97      1.00      0.99        35\n",
      "           8       0.97      0.95      0.96        37\n",
      "           9       1.00      0.93      0.97        45\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 섞기 및 학습\n",
    "for i in range(5):\n",
    "    X2_train, X2_test, y2_train, y2_test = train_test_split(digits_data, \n",
    "                                                    digits_label, \n",
    "                                                    test_size=0.2)\n",
    "                                                                                                \n",
    "    random_forest = RandomForestClassifier()\n",
    "    random_forest.fit(X2_train, y2_train)\n",
    "    y2_pred = random_forest.predict(X2_test)\n",
    "\n",
    "    accuracy2 = accuracy_score(y2_test, y2_pred)\n",
    "    print(accuracy2)\n",
    "    print(classification_report(y2_test, y2_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2b04e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "0.9972222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        37\n",
      "           1       1.00      1.00      1.00        37\n",
      "           2       1.00      1.00      1.00        19\n",
      "           3       1.00      1.00      1.00        43\n",
      "           4       1.00      0.97      0.98        31\n",
      "           5       1.00      1.00      1.00        34\n",
      "           6       1.00      1.00      1.00        46\n",
      "           7       1.00      1.00      1.00        36\n",
      "           8       0.98      1.00      0.99        40\n",
      "           9       1.00      1.00      1.00        37\n",
      "\n",
      "    accuracy                           1.00       360\n",
      "   macro avg       1.00      1.00      1.00       360\n",
      "weighted avg       1.00      1.00      1.00       360\n",
      "\n",
      "0.9916666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        41\n",
      "           1       1.00      1.00      1.00        35\n",
      "           2       1.00      1.00      1.00        28\n",
      "           3       1.00      1.00      1.00        31\n",
      "           4       1.00      1.00      1.00        42\n",
      "           5       1.00      0.97      0.99        37\n",
      "           6       1.00      1.00      1.00        40\n",
      "           7       0.97      0.97      0.97        29\n",
      "           8       1.00      1.00      1.00        38\n",
      "           9       0.95      0.97      0.96        39\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "0.9944444444444445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "           1       0.97      1.00      0.99        39\n",
      "           2       1.00      1.00      1.00        37\n",
      "           3       1.00      1.00      1.00        31\n",
      "           4       1.00      1.00      1.00        36\n",
      "           5       1.00      1.00      1.00        40\n",
      "           6       1.00      1.00      1.00        29\n",
      "           7       0.97      1.00      0.99        38\n",
      "           8       1.00      0.98      0.99        41\n",
      "           9       1.00      0.97      0.98        33\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "0.9944444444444445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        27\n",
      "           1       1.00      1.00      1.00        47\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      1.00      1.00        44\n",
      "           4       1.00      1.00      1.00        34\n",
      "           5       1.00      1.00      1.00        45\n",
      "           6       1.00      1.00      1.00        34\n",
      "           7       0.98      1.00      0.99        44\n",
      "           8       0.96      1.00      0.98        22\n",
      "           9       1.00      0.93      0.97        30\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "0.9944444444444445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "           1       0.96      1.00      0.98        26\n",
      "           2       1.00      1.00      1.00        41\n",
      "           3       1.00      1.00      1.00        31\n",
      "           4       1.00      1.00      1.00        28\n",
      "           5       1.00      1.00      1.00        33\n",
      "           6       1.00      1.00      1.00        43\n",
      "           7       1.00      1.00      1.00        48\n",
      "           8       0.97      0.97      0.97        39\n",
      "           9       1.00      0.97      0.99        35\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# svm 모델\n",
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "print(svm_model._estimator_type)\n",
    "\n",
    "# 섞기 및 학습\n",
    "for i in range(5):\n",
    "    X3_train, X3_test, y3_train, y3_test = train_test_split(digits_data, \n",
    "                                                    digits_label, \n",
    "                                                    test_size=0.2)\n",
    "                                                                                                \n",
    "    random_forest = RandomForestClassifier()\n",
    "    random_forest.fit(X3_train, y3_train)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y3_pred = svm_model.predict(X3_test)\n",
    "\n",
    "\n",
    "\n",
    "    accuracy3 = accuracy_score(y3_test, y3_pred)\n",
    "    print(accuracy3)\n",
    "    print(classification_report(y3_test, y3_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e66412e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "0.075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.10      0.10        41\n",
      "           1       0.03      0.03      0.03        36\n",
      "           2       0.03      0.03      0.03        35\n",
      "           3       0.02      0.02      0.02        41\n",
      "           4       0.15      0.18      0.16        33\n",
      "           5       0.05      0.08      0.06        26\n",
      "           6       0.11      0.07      0.09        41\n",
      "           7       0.10      0.10      0.10        29\n",
      "           8       0.10      0.11      0.10        38\n",
      "           9       0.07      0.05      0.06        40\n",
      "\n",
      "    accuracy                           0.07       360\n",
      "   macro avg       0.08      0.08      0.08       360\n",
      "weighted avg       0.08      0.07      0.07       360\n",
      "\n",
      "0.08888888888888889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.07      0.06        30\n",
      "           1       0.15      0.14      0.14        36\n",
      "           2       0.08      0.08      0.08        39\n",
      "           3       0.05      0.05      0.05        43\n",
      "           4       0.13      0.13      0.13        39\n",
      "           5       0.08      0.08      0.08        38\n",
      "           6       0.10      0.10      0.10        31\n",
      "           7       0.10      0.09      0.09        35\n",
      "           8       0.07      0.08      0.08        36\n",
      "           9       0.09      0.09      0.09        33\n",
      "\n",
      "    accuracy                           0.09       360\n",
      "   macro avg       0.09      0.09      0.09       360\n",
      "weighted avg       0.09      0.09      0.09       360\n",
      "\n",
      "0.10833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.14      0.12        29\n",
      "           1       0.15      0.13      0.14        38\n",
      "           2       0.11      0.08      0.09        49\n",
      "           3       0.05      0.06      0.05        33\n",
      "           4       0.05      0.07      0.06        29\n",
      "           5       0.16      0.17      0.16        36\n",
      "           6       0.13      0.12      0.12        34\n",
      "           7       0.10      0.07      0.08        41\n",
      "           8       0.13      0.14      0.14        35\n",
      "           9       0.12      0.11      0.12        36\n",
      "\n",
      "    accuracy                           0.11       360\n",
      "   macro avg       0.11      0.11      0.11       360\n",
      "weighted avg       0.11      0.11      0.11       360\n",
      "\n",
      "0.11388888888888889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.06      0.06        31\n",
      "           1       0.13      0.12      0.12        43\n",
      "           2       0.17      0.19      0.18        32\n",
      "           3       0.08      0.08      0.08        38\n",
      "           4       0.10      0.11      0.11        36\n",
      "           5       0.24      0.23      0.23        44\n",
      "           6       0.14      0.09      0.11        43\n",
      "           7       0.03      0.03      0.03        31\n",
      "           8       0.08      0.11      0.09        27\n",
      "           9       0.10      0.09      0.09        35\n",
      "\n",
      "    accuracy                           0.11       360\n",
      "   macro avg       0.11      0.11      0.11       360\n",
      "weighted avg       0.12      0.11      0.11       360\n",
      "\n",
      "0.10833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.19      0.17        31\n",
      "           1       0.11      0.10      0.10        40\n",
      "           2       0.17      0.17      0.17        36\n",
      "           3       0.09      0.11      0.10        35\n",
      "           4       0.05      0.06      0.06        32\n",
      "           5       0.10      0.12      0.11        34\n",
      "           6       0.13      0.12      0.13        32\n",
      "           7       0.10      0.08      0.09        36\n",
      "           8       0.08      0.08      0.08        38\n",
      "           9       0.12      0.07      0.08        46\n",
      "\n",
      "    accuracy                           0.11       360\n",
      "   macro avg       0.11      0.11      0.11       360\n",
      "weighted avg       0.11      0.11      0.11       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#SGD Classifier 모델\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "print(sgd_model._estimator_type)\n",
    "\n",
    "\n",
    "# 섞기 및 학습\n",
    "for i in range(5):\n",
    "    X4_train, X4_test, y4_train, y4_test = train_test_split(digits_data, \n",
    "                                                    digits_label, \n",
    "                                                    test_size=0.2)\n",
    "                                                                                                \n",
    "    \n",
    "    sgd_model.fit(X4_train, y4_train)\n",
    "    y4_pred = sgd_model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "    accuracy4 = accuracy_score(y4_test, y4_pred)\n",
    "    print(accuracy4)\n",
    "    print(classification_report(y4_test, y4_pred))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bd94185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "0.9944444444444445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        37\n",
      "           1       1.00      1.00      1.00        36\n",
      "           2       1.00      1.00      1.00        47\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      0.97      0.99        37\n",
      "           5       1.00      1.00      1.00        25\n",
      "           6       1.00      1.00      1.00        39\n",
      "           7       1.00      1.00      1.00        40\n",
      "           8       0.95      1.00      0.97        35\n",
      "           9       1.00      0.97      0.98        30\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "0.9944444444444445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        37\n",
      "           1       1.00      1.00      1.00        36\n",
      "           2       1.00      1.00      1.00        47\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      0.97      0.99        37\n",
      "           5       1.00      1.00      1.00        25\n",
      "           6       1.00      1.00      1.00        39\n",
      "           7       1.00      1.00      1.00        40\n",
      "           8       0.95      1.00      0.97        35\n",
      "           9       1.00      0.97      0.98        30\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "0.9944444444444445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        37\n",
      "           1       1.00      1.00      1.00        36\n",
      "           2       1.00      1.00      1.00        47\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      0.97      0.99        37\n",
      "           5       1.00      1.00      1.00        25\n",
      "           6       1.00      1.00      1.00        39\n",
      "           7       1.00      1.00      1.00        40\n",
      "           8       0.95      1.00      0.97        35\n",
      "           9       1.00      0.97      0.98        30\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "0.9944444444444445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        37\n",
      "           1       1.00      1.00      1.00        36\n",
      "           2       1.00      1.00      1.00        47\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      0.97      0.99        37\n",
      "           5       1.00      1.00      1.00        25\n",
      "           6       1.00      1.00      1.00        39\n",
      "           7       1.00      1.00      1.00        40\n",
      "           8       0.95      1.00      0.97        35\n",
      "           9       1.00      0.97      0.98        30\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "0.9944444444444445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        37\n",
      "           1       1.00      1.00      1.00        36\n",
      "           2       1.00      1.00      1.00        47\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      0.97      0.99        37\n",
      "           5       1.00      1.00      1.00        25\n",
      "           6       1.00      1.00      1.00        39\n",
      "           7       1.00      1.00      1.00        40\n",
      "           8       0.95      1.00      0.97        35\n",
      "           9       1.00      0.97      0.98        30\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression 모델\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression(max_iter=3000)\n",
    "# https://url.kr/aqxgue에서 max_iter=(3000)를 알게됨\n",
    "\n",
    "print(logistic_model._estimator_type)\n",
    "\n",
    "\n",
    "# 섞기 및 학습\n",
    "\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(digits_data, \n",
    "                                                    digits_label, \n",
    "                                                    test_size=0.2)\n",
    "                                                                                                \n",
    "for i in range(5):  # 계산하는데 시간이 어느정도 걸린다.\n",
    "    logistic_model.fit(X_train, y_train)\n",
    "    y5_pred = logistic_model.predict(X5_test)\n",
    "\n",
    "    accuracy5 = accuracy_score(y5_test, y5_pred)\n",
    "    print(accuracy5)\n",
    "    print(classification_report(y5_test, y5_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa46e727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8369f880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a13859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0208c80",
   "metadata": {},
   "source": [
    "# load_wine의 5가지의 학습 모델 중 Logistic Regression 모델의 accuracy가 가장 정확도가 높았다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "511dad6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<class 'sklearn.utils.Bunch'>\n",
      "딕션너리 키:  dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])\n",
      "\n",
      "\n",
      "데이터: (178, 13)\n",
      "\n",
      "\n",
      "윤곽:  None\n",
      "\n",
      "\n",
      "문제지 이름(항목):  ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "\n",
      "\n",
      "정답지 이름(카테고리):  ['class_0' 'class_1' 'class_2']\n",
      "\n",
      "\n",
      "정답지 번호(일련번호):  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      "\n",
      "(178, 13)\n",
      "(178,)\n",
      "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
      "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
      "..       ...         ...   ...                ...        ...            ...   \n",
      "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
      "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
      "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
      "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
      "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
      "\n",
      "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0          3.06                  0.28             2.29             5.64  1.04   \n",
      "1          2.76                  0.26             1.28             4.38  1.05   \n",
      "2          3.24                  0.30             2.81             5.68  1.03   \n",
      "3          3.49                  0.24             2.18             7.80  0.86   \n",
      "4          2.69                  0.39             1.82             4.32  1.04   \n",
      "..          ...                   ...              ...              ...   ...   \n",
      "173        0.61                  0.52             1.06             7.70  0.64   \n",
      "174        0.75                  0.43             1.41             7.30  0.70   \n",
      "175        0.69                  0.43             1.35            10.20  0.59   \n",
      "176        0.68                  0.53             1.46             9.30  0.60   \n",
      "177        0.76                  0.56             1.35             9.20  0.61   \n",
      "\n",
      "     od280/od315_of_diluted_wines  proline  label  \n",
      "0                            3.92   1065.0      0  \n",
      "1                            3.40   1050.0      0  \n",
      "2                            3.17   1185.0      0  \n",
      "3                            3.45   1480.0      0  \n",
      "4                            2.93    735.0      0  \n",
      "..                            ...      ...    ...  \n",
      "173                          1.74    740.0      2  \n",
      "174                          1.56    750.0      2  \n",
      "175                          1.56    835.0      2  \n",
      "176                          1.62    840.0      2  \n",
      "177                          1.60    560.0      2  \n",
      "\n",
      "[178 rows x 14 columns]\n",
      "X_train 개수:  142 , X_test 개수:  36\n",
      "classifier\n",
      "0.8611111111111112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        13\n",
      "           1       0.75      0.92      0.83        13\n",
      "           2       0.89      0.80      0.84        10\n",
      "\n",
      "    accuracy                           0.86        36\n",
      "   macro avg       0.88      0.86      0.86        36\n",
      "weighted avg       0.88      0.86      0.86        36\n",
      "\n",
      "X_train 개수:  142 , X_test 개수:  36\n",
      "classifier\n",
      "0.9444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94         8\n",
      "           1       0.94      0.94      0.94        16\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.94      0.95      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "X_train 개수:  142 , X_test 개수:  36\n",
      "classifier\n",
      "0.9722222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        15\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.97      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "X_train 개수:  142 , X_test 개수:  36\n",
      "classifier\n",
      "0.9722222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.94      0.97        16\n",
      "           2       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.97      0.98      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "X_train 개수:  142 , X_test 개수:  36\n",
      "classifier\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90        15\n",
      "           1       0.83      1.00      0.91        10\n",
      "           2       1.00      0.91      0.95        11\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.92      0.93      0.92        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      "\n",
      "0.9722222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      0.94      0.97        17\n",
      "           2       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.95      0.98      0.96        36\n",
      "weighted avg       0.98      0.97      0.97        36\n",
      "\n",
      "0.9722222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.97      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "0.9722222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.93      0.96        14\n",
      "           2       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.98      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "0.9444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.87      0.93        15\n",
      "           2       0.85      1.00      0.92        11\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.95      0.96      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "classifier\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88        13\n",
      "           1       0.54      0.93      0.68        14\n",
      "           2       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.67        36\n",
      "   macro avg       0.49      0.59      0.52        36\n",
      "weighted avg       0.54      0.67      0.58        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7777777777777778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90        16\n",
      "           1       0.67      0.93      0.78        15\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.78        36\n",
      "   macro avg       0.53      0.60      0.56        36\n",
      "weighted avg       0.69      0.78      0.73        36\n",
      "\n",
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93        13\n",
      "           1       0.67      0.88      0.76        16\n",
      "           2       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.75        36\n",
      "   macro avg       0.51      0.62      0.56        36\n",
      "weighted avg       0.61      0.75      0.67        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7777777777777778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        13\n",
      "           1       0.70      1.00      0.82        16\n",
      "           2       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.78        36\n",
      "   macro avg       0.54      0.64      0.58        36\n",
      "weighted avg       0.64      0.78      0.70        36\n",
      "\n",
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.82         8\n",
      "           1       0.85      0.92      0.88        25\n",
      "           2       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.83        36\n",
      "   macro avg       0.54      0.60      0.57        36\n",
      "weighted avg       0.76      0.83      0.80        36\n",
      "\n",
      "classifier\n",
      "0.5185185185185185\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      1.00      0.65        15\n",
      "           1       0.55      0.63      0.59        19\n",
      "           2       1.00      0.05      0.10        20\n",
      "\n",
      "    accuracy                           0.52        54\n",
      "   macro avg       0.68      0.56      0.44        54\n",
      "weighted avg       0.70      0.52      0.42        54\n",
      "\n",
      "0.5370370370370371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.95      0.68        19\n",
      "           1       0.55      0.65      0.59        17\n",
      "           2       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.54        54\n",
      "   macro avg       0.36      0.53      0.42        54\n",
      "weighted avg       0.36      0.54      0.43        54\n",
      "\n",
      "0.6481481481481481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.69        19\n",
      "           1       1.00      0.46      0.63        24\n",
      "           2       0.71      0.45      0.56        11\n",
      "\n",
      "    accuracy                           0.65        54\n",
      "   macro avg       0.75      0.64      0.63        54\n",
      "weighted avg       0.78      0.65      0.64        54\n",
      "\n",
      "0.6296296296296297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.81      0.90        16\n",
      "           1       0.51      1.00      0.68        21\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.63        54\n",
      "   macro avg       0.50      0.60      0.52        54\n",
      "weighted avg       0.50      0.63      0.53        54\n",
      "\n",
      "0.5370370370370371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      1.00      0.56        12\n",
      "           1       0.74      0.71      0.72        24\n",
      "           2       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.54        54\n",
      "   macro avg       0.38      0.57      0.43        54\n",
      "weighted avg       0.41      0.54      0.45        54\n",
      "\n",
      "classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yun/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       0.89      0.80      0.84        10\n",
      "           2       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.91      0.90      0.90        36\n",
      "weighted avg       0.92      0.92      0.91        36\n",
      "\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       0.89      0.80      0.84        10\n",
      "           2       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.91      0.90      0.90        36\n",
      "weighted avg       0.92      0.92      0.91        36\n",
      "\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       0.89      0.80      0.84        10\n",
      "           2       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.91      0.90      0.90        36\n",
      "weighted avg       0.92      0.92      0.91        36\n",
      "\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       0.89      0.80      0.84        10\n",
      "           2       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.91      0.90      0.90        36\n",
      "weighted avg       0.92      0.92      0.91        36\n",
      "\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       0.89      0.80      0.84        10\n",
      "           2       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.91      0.90      0.90        36\n",
      "weighted avg       0.92      0.92      0.91        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# https://url.kr/3t2y1f 참조.\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine(); print('\\n')\n",
    "\n",
    "print(type(wine))\n",
    "\n",
    "print('딕션너리 키: ', wine.keys()); print('\\n') # 항목을 확인함.\n",
    "\n",
    "print('데이터:', wine.data.shape); print('\\n')\n",
    "print('윤곽: ', wine.frame); print('\\n')\n",
    "print('문제지 이름(항목): ', wine.feature_names); print('\\n')\n",
    "print('정답지 이름(카테고리): ', wine.target_names); print('\\n')\n",
    "print('정답지 번호(일련번호): ', wine.target); print('\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 시각화\n",
    "\n",
    "wine_data = wine.data\n",
    "wine_label = wine.target\n",
    "\n",
    "\n",
    "wine_df = pd.DataFrame(data = wine_data,\n",
    "                       columns = wine.feature_names)\n",
    "\n",
    "wine_df[\"label\"] = wine.target\n",
    "\n",
    "print(wine_data.shape)\n",
    "print(wine_label.shape)\n",
    "print(wine_df)\n",
    "\n",
    "# 5가지의  학습모델 중 RandomForestClassifier의 정확도가 가장 컸다.\n",
    "\n",
    "\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# 섞기 및 학습\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(wine_data, \n",
    "                                                    wine_label, \n",
    "                                                    test_size =0.2, \n",
    "                                                    )\n",
    "\n",
    "    print('X_train 개수: ', len(X_train),', X_test 개수: ', len(X_test))\n",
    "    X_train.shape, y_train.shape # 확인\n",
    "    X_test.shape, y_test.shape  # 확인\n",
    "\n",
    "    decision_tree = DecisionTreeClassifier()\n",
    "    print(decision_tree._estimator_type)\n",
    "\n",
    "    # 학습 \n",
    "    decision_tree.fit(X_train, y_train)\n",
    "\n",
    "    #예측\n",
    "    y_pred = decision_tree.predict(X_test)\n",
    "    y_pred\n",
    "\n",
    "     #정확도\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(accuracy)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 섞기 및 학습\n",
    "for i in range(5):\n",
    "    X2_train, X2_test, y2_train, y2_test = train_test_split(wine_data, \n",
    "                                                    wine_label, \n",
    "                                                    test_size=0.2)\n",
    "                                                                                                \n",
    "    random_forest = RandomForestClassifier()\n",
    "    random_forest.fit(X2_train, y2_train)\n",
    "    y2_pred = random_forest.predict(X2_test)\n",
    "\n",
    "    accuracy2 = accuracy_score(y2_test, y2_pred)\n",
    "    print(accuracy2)\n",
    "    print(classification_report(y2_test, y2_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# svm 모델\n",
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "print(svm_model._estimator_type)\n",
    "\n",
    "# 섞기 및 학습\n",
    "for i in range(5):\n",
    "    X3_train, X3_test, y3_train, y3_test = train_test_split(wine_data, \n",
    "                                                    wine_label, \n",
    "                                                    test_size=0.2)\n",
    "                                                                                                \n",
    "    random_forest = RandomForestClassifier()\n",
    "    random_forest.fit(X3_train, y3_train)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y3_pred = svm_model.predict(X3_test)\n",
    "\n",
    "\n",
    "\n",
    "    accuracy3 = accuracy_score(y3_test, y3_pred)\n",
    "    print(accuracy3)\n",
    "    print(classification_report(y3_test, y3_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#SGD Classifier 모델\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "print(sgd_model._estimator_type)\n",
    "\n",
    "\n",
    "# 섞기 및 학습\n",
    "for i in range(5):\n",
    "    X4_train, X4_test, y4_train, y4_test = train_test_split(wine_data, \n",
    "                                                    wine_label, \n",
    "                                                    test_size=0.3)\n",
    "                                                                                                \n",
    "    \n",
    "    sgd_model.fit(X4_train, y4_train)\n",
    "    y4_pred = sgd_model.predict(X4_test)\n",
    "\n",
    "\n",
    "\n",
    "    accuracy4 = accuracy_score(y4_test, y4_pred)\n",
    "    print(accuracy4)\n",
    "    print(classification_report(y4_test, y4_pred))\n",
    "\n",
    "#Logistic Regression 모델\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression(max_iter=3000)\n",
    "# https://url.kr/aqxgue에서 max_iter=(3000)를 알게됨\n",
    "\n",
    "print(logistic_model._estimator_type)\n",
    "\n",
    "\n",
    "# 섞기 및 학습\n",
    "\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(wine_data, \n",
    "                                                    wine_label, \n",
    "                                                    test_size=0.2)\n",
    "                                                                                                \n",
    "for i in range(5):  # 계산하는데 시간이 어느정도 걸린다.\n",
    "    logistic_model.fit(X5_train, y5_train)\n",
    "    y5_pred = logistic_model.predict(X5_test)\n",
    "\n",
    "    accuracy5 = accuracy_score(y5_test, y5_pred)\n",
    "    print(accuracy5)\n",
    "    print(classification_report(y5_test, y5_pred))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b27e44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855ac6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdcc77de",
   "metadata": {},
   "source": [
    "# load_breast_cancer의 5가지의 학습 모델 중 Logistic Regression 모델의 accuracy가 가장 정확도가 높았다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fc95a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
      "<class 'sklearn.utils.Bunch'>\n",
      "딕션너리 키:  dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
      "\n",
      "\n",
      "데이터: [[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n",
      "\n",
      "\n",
      "윤곽:  None\n",
      "\n",
      "\n",
      "문제지 이름(항목):  ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "\n",
      "\n",
      "정답지 이름(카테고리):  ['malignant' 'benign']\n",
      "\n",
      "\n",
      "정답지 번호(일련번호):  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
      "\n",
      "\n",
      "데이터 모듈:  sklearn.datasets.data\n",
      "\n",
      "\n",
      "(569, 30)\n",
      "(569,)\n",
      "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0          17.99         10.38          122.80     1001.0          0.11840   \n",
      "1          20.57         17.77          132.90     1326.0          0.08474   \n",
      "2          19.69         21.25          130.00     1203.0          0.10960   \n",
      "3          11.42         20.38           77.58      386.1          0.14250   \n",
      "4          20.29         14.34          135.10     1297.0          0.10030   \n",
      "..           ...           ...             ...        ...              ...   \n",
      "564        21.56         22.39          142.00     1479.0          0.11100   \n",
      "565        20.13         28.25          131.20     1261.0          0.09780   \n",
      "566        16.60         28.08          108.30      858.1          0.08455   \n",
      "567        20.60         29.33          140.10     1265.0          0.11780   \n",
      "568         7.76         24.54           47.92      181.0          0.05263   \n",
      "\n",
      "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0             0.27760         0.30010              0.14710         0.2419   \n",
      "1             0.07864         0.08690              0.07017         0.1812   \n",
      "2             0.15990         0.19740              0.12790         0.2069   \n",
      "3             0.28390         0.24140              0.10520         0.2597   \n",
      "4             0.13280         0.19800              0.10430         0.1809   \n",
      "..                ...             ...                  ...            ...   \n",
      "564           0.11590         0.24390              0.13890         0.1726   \n",
      "565           0.10340         0.14400              0.09791         0.1752   \n",
      "566           0.10230         0.09251              0.05302         0.1590   \n",
      "567           0.27700         0.35140              0.15200         0.2397   \n",
      "568           0.04362         0.00000              0.00000         0.1587   \n",
      "\n",
      "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                   0.07871  ...          17.33           184.60      2019.0   \n",
      "1                   0.05667  ...          23.41           158.80      1956.0   \n",
      "2                   0.05999  ...          25.53           152.50      1709.0   \n",
      "3                   0.09744  ...          26.50            98.87       567.7   \n",
      "4                   0.05883  ...          16.67           152.20      1575.0   \n",
      "..                      ...  ...            ...              ...         ...   \n",
      "564                 0.05623  ...          26.40           166.10      2027.0   \n",
      "565                 0.05533  ...          38.25           155.00      1731.0   \n",
      "566                 0.05648  ...          34.12           126.70      1124.0   \n",
      "567                 0.07016  ...          39.42           184.60      1821.0   \n",
      "568                 0.05884  ...          30.37            59.16       268.6   \n",
      "\n",
      "     worst smoothness  worst compactness  worst concavity  \\\n",
      "0             0.16220            0.66560           0.7119   \n",
      "1             0.12380            0.18660           0.2416   \n",
      "2             0.14440            0.42450           0.4504   \n",
      "3             0.20980            0.86630           0.6869   \n",
      "4             0.13740            0.20500           0.4000   \n",
      "..                ...                ...              ...   \n",
      "564           0.14100            0.21130           0.4107   \n",
      "565           0.11660            0.19220           0.3215   \n",
      "566           0.11390            0.30940           0.3403   \n",
      "567           0.16500            0.86810           0.9387   \n",
      "568           0.08996            0.06444           0.0000   \n",
      "\n",
      "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
      "0                  0.2654          0.4601                  0.11890      0  \n",
      "1                  0.1860          0.2750                  0.08902      0  \n",
      "2                  0.2430          0.3613                  0.08758      0  \n",
      "3                  0.2575          0.6638                  0.17300      0  \n",
      "4                  0.1625          0.2364                  0.07678      0  \n",
      "..                    ...             ...                      ...    ...  \n",
      "564                0.2216          0.2060                  0.07115      0  \n",
      "565                0.1628          0.2572                  0.06637      0  \n",
      "566                0.1418          0.2218                  0.07820      0  \n",
      "567                0.2650          0.4087                  0.12400      0  \n",
      "568                0.0000          0.2871                  0.07039      1  \n",
      "\n",
      "[569 rows x 31 columns]\n",
      "X_train 개수:  455 , X_test 개수:  114\n",
      "classifier\n",
      "0.9298245614035088\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91        43\n",
      "           1       0.96      0.93      0.94        71\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.92      0.93      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "X_train 개수:  455 , X_test 개수:  114\n",
      "classifier\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90        43\n",
      "           1       0.96      0.92      0.94        71\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.91      0.92      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "X_train 개수:  455 , X_test 개수:  114\n",
      "classifier\n",
      "0.8771929824561403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84        43\n",
      "           1       0.93      0.87      0.90        71\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.87      0.88      0.87       114\n",
      "weighted avg       0.88      0.88      0.88       114\n",
      "\n",
      "X_train 개수:  455 , X_test 개수:  114\n",
      "classifier\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89        41\n",
      "           1       0.96      0.92      0.94        73\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.91      0.92      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "X_train 개수:  455 , X_test 개수:  114\n",
      "classifier\n",
      "0.9473684210526315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93        43\n",
      "           1       0.95      0.97      0.96        71\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.956140350877193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95        47\n",
      "           1       0.97      0.96      0.96        67\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.95      0.96      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "0.956140350877193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.94        41\n",
      "           1       0.95      0.99      0.97        73\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.94      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "0.9824561403508771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        40\n",
      "           1       0.99      0.99      0.99        74\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.98      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "0.9473684210526315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92        40\n",
      "           1       0.94      0.99      0.96        74\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "0.9736842105263158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "classifier\n",
      "0.9035087719298246\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86        44\n",
      "           1       0.86      1.00      0.93        70\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.93      0.88      0.89       114\n",
      "weighted avg       0.92      0.90      0.90       114\n",
      "\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89        46\n",
      "           1       0.88      1.00      0.94        68\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.94      0.90      0.91       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "0.8596491228070176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.69      0.81        49\n",
      "           1       0.81      0.98      0.89        65\n",
      "\n",
      "    accuracy                           0.86       114\n",
      "   macro avg       0.89      0.84      0.85       114\n",
      "weighted avg       0.88      0.86      0.85       114\n",
      "\n",
      "0.8947368421052632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.74      0.84        42\n",
      "           1       0.87      0.99      0.92        72\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.92      0.86      0.88       114\n",
      "weighted avg       0.90      0.89      0.89       114\n",
      "\n",
      "0.9035087719298246\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.77      0.86        44\n",
      "           1       0.87      0.99      0.93        70\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.92      0.88      0.89       114\n",
      "weighted avg       0.91      0.90      0.90       114\n",
      "\n",
      "classifier\n",
      "0.631578947368421\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.10      0.16        39\n",
      "           1       0.66      0.91      0.76        75\n",
      "\n",
      "    accuracy                           0.63       114\n",
      "   macro avg       0.51      0.50      0.46       114\n",
      "weighted avg       0.56      0.63      0.56       114\n",
      "\n",
      "0.543859649122807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.32      0.33        41\n",
      "           1       0.64      0.67      0.65        73\n",
      "\n",
      "    accuracy                           0.54       114\n",
      "   macro avg       0.49      0.49      0.49       114\n",
      "weighted avg       0.53      0.54      0.54       114\n",
      "\n",
      "0.543859649122807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.33      0.35        43\n",
      "           1       0.62      0.68      0.65        71\n",
      "\n",
      "    accuracy                           0.54       114\n",
      "   macro avg       0.50      0.50      0.50       114\n",
      "weighted avg       0.53      0.54      0.54       114\n",
      "\n",
      "0.5701754385964912\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.28      0.33        43\n",
      "           1       0.63      0.75      0.68        71\n",
      "\n",
      "    accuracy                           0.57       114\n",
      "   macro avg       0.52      0.51      0.51       114\n",
      "weighted avg       0.54      0.57      0.55       114\n",
      "\n",
      "0.6140350877192983\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.28      0.33        39\n",
      "           1       0.68      0.79      0.73        75\n",
      "\n",
      "    accuracy                           0.61       114\n",
      "   macro avg       0.54      0.53      0.53       114\n",
      "weighted avg       0.59      0.61      0.59       114\n",
      "\n",
      "classifier\n",
      "0.9649122807017544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        46\n",
      "           1       0.98      0.96      0.97        68\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.97      0.96       114\n",
      "weighted avg       0.97      0.96      0.97       114\n",
      "\n",
      "0.9649122807017544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        46\n",
      "           1       0.98      0.96      0.97        68\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.97      0.96       114\n",
      "weighted avg       0.97      0.96      0.97       114\n",
      "\n",
      "0.9649122807017544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        46\n",
      "           1       0.98      0.96      0.97        68\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.97      0.96       114\n",
      "weighted avg       0.97      0.96      0.97       114\n",
      "\n",
      "0.9649122807017544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        46\n",
      "           1       0.98      0.96      0.97        68\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.97      0.96       114\n",
      "weighted avg       0.97      0.96      0.97       114\n",
      "\n",
      "0.9649122807017544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        46\n",
      "           1       0.98      0.96      0.97        68\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.97      0.96       114\n",
      "weighted avg       0.97      0.96      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://url.kr/ayorp2 참고 사이트\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = load_breast_cancer() # 원래는 cancer,breast_cancer 등으로 할려고 했으나 \n",
    "                            #자꾸 import가 되지 않았습니다.(type이 function)\n",
    "                            # 위쪽의 링크를 복사 붙여넣기를 하니 import가되어서 변수명을 data로 했습니다.\n",
    "\n",
    "\n",
    "print(data.keys())\n",
    "\n",
    "\n",
    "\n",
    "print(type(data))\n",
    "\n",
    "print('딕션너리 키: ', data.keys()); print('\\n') # 항목을 확인함.\n",
    "\n",
    "print('데이터:', data.data); print('\\n')\n",
    "print('윤곽: ', data.frame); print('\\n')\n",
    "print('문제지 이름(항목): ', data.feature_names); print('\\n')\n",
    "print('정답지 이름(카테고리): ', data.target_names); print('\\n')\n",
    "print('정답지 번호(일련번호): ', data.target); print('\\n')\n",
    "print('데이터 모듈: ', data.data_module); print('\\n')\n",
    "\n",
    "# 시각화\n",
    "data_data = data.data\n",
    "data_label = data.target\n",
    "\n",
    "\n",
    "data_df = pd.DataFrame(data = data_data,\n",
    "                       columns = data.feature_names)\n",
    "\n",
    "data_df[\"label\"] = data.target\n",
    "\n",
    "print(data_data.shape)\n",
    "print(data_label.shape)\n",
    "print(data_df)\n",
    "\n",
    "# 5가지의 학습모델 중에서 Logistic Regression 모델이 정확도가 가장 높았다.\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# 섞기 및 학습\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_data, \n",
    "                                                    data_label, \n",
    "                                                    test_size =0.2, \n",
    "                                                    )\n",
    "\n",
    "    print('X_train 개수: ', len(X_train),', X_test 개수: ', len(X_test))\n",
    "    X_train.shape, y_train.shape # 확인\n",
    "    X_test.shape, y_test.shape  # 확인\n",
    "\n",
    "    decision_tree = DecisionTreeClassifier()\n",
    "    print(decision_tree._estimator_type)\n",
    "\n",
    "    # 학습 \n",
    "    decision_tree.fit(X_train, y_train)\n",
    "\n",
    "    #예측\n",
    "    y_pred = decision_tree.predict(X_test)\n",
    "    y_pred\n",
    "\n",
    "     #정확도\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(accuracy)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 섞기 및 학습\n",
    "for i in range(5):\n",
    "    X2_train, X2_test, y2_train, y2_test = train_test_split(data_data, \n",
    "                                                    data_label, \n",
    "                                                    test_size=0.2)\n",
    "                                                                                                \n",
    "    random_forest = RandomForestClassifier()\n",
    "    random_forest.fit(X2_train, y2_train)\n",
    "    y2_pred = random_forest.predict(X2_test)\n",
    "\n",
    "    accuracy2 = accuracy_score(y2_test, y2_pred)\n",
    "    print(accuracy2)\n",
    "    print(classification_report(y2_test, y2_pred))\n",
    "\n",
    "# svm 모델\n",
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "print(svm_model._estimator_type)\n",
    "\n",
    "# 섞기 및 학습\n",
    "for i in range(5):\n",
    "    X3_train, X3_test, y3_train, y3_test = train_test_split(data_data, \n",
    "                                                    data_label, \n",
    "                                                    test_size=0.2)\n",
    "                                                                                                \n",
    "    random_forest = RandomForestClassifier()\n",
    "    random_forest.fit(X3_train, y3_train)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y3_pred = svm_model.predict(X3_test)\n",
    "\n",
    "\n",
    "\n",
    "    accuracy3 = accuracy_score(y3_test, y3_pred)\n",
    "    print(accuracy3)\n",
    "    print(classification_report(y3_test, y3_pred))\n",
    "\n",
    "#SGD Classifier 모델\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "print(sgd_model._estimator_type)\n",
    "\n",
    "\n",
    "# 섞기 및 학습\n",
    "for i in range(5):\n",
    "    X4_train, X4_test, y4_train, y4_test = train_test_split(data_data, \n",
    "                                                    data_label, \n",
    "                                                    test_size=0.2)\n",
    "                                                                                                \n",
    "    \n",
    "    sgd_model.fit(X4_train, y4_train)\n",
    "    y4_pred = sgd_model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "    accuracy4 = accuracy_score(y4_test, y4_pred)\n",
    "    print(accuracy4)\n",
    "    print(classification_report(y4_test, y4_pred))\n",
    "\n",
    "#Logistic Regression 모델\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression(max_iter=3000)\n",
    "# https://url.kr/aqxgue에서 max_iter=(3000)를 알게됨\n",
    "\n",
    "print(logistic_model._estimator_type)\n",
    "\n",
    "\n",
    "# 섞기 및 학습\n",
    "\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(data_data, \n",
    "                                                    data_label, \n",
    "                                                    test_size=0.2)\n",
    "                                                                                                \n",
    "for i in range(5):  # 계산하는데 시간이 어느정도 걸린다.\n",
    "    logistic_model.fit(X5_train, y5_train)\n",
    "    y5_pred = logistic_model.predict(X5_test)\n",
    "\n",
    "    accuracy5 = accuracy_score(y5_test, y5_pred)\n",
    "    print(accuracy5)\n",
    "    print(classification_report(y5_test, y5_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
